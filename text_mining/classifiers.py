# -*- coding: utf-8 -*-
"""IST736_Project_Group_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pVzNwdi07I2VXf_P_sfaGs61WRoMBOTm

#**IST 736 Project Group 3**
#Jack O'Connor
#Kyle Wass
#Chen Zhou
#Nicolas Reyes
"""

#mounting googledrive
from google.colab import drive
drive.mount('/content/gdrive')

#Loading packages
import pandas as pd 
import numpy as np  
import nltk
import sklearn
import re
import os
import string
import random as rd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.model_selection import cross_val_score
from sklearn.metrics import confusion_matrix
from matplotlib import figure
from nltk import word_tokenize          
from nltk.stem import WordNetLemmatizer 
from sklearn.svm import LinearSVC
nltk.download('punkt')
nltk.download('wordnet')
from sklearn.metrics import plot_confusion_matrix, classification_report
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import learning_curve, GridSearchCV
from sklearn import svm
from sklearn.svm import SVC 
from sklearn.model_selection import GridSearchCV

#Setting reviews file path to a variable
train = pd.read_csv('/content/gdrive/MyDrive/train_data_group_3_final.csv')

trainDF = pd.DataFrame (train, columns = ['search_term', 'country',])

ax = trainDF['search_term'].value_counts().plot(kind='bar',figsize=(14,8), title="Article Frequency")

trainDF['search_term'].value_counts()

trainDF['country'].value_counts()

ax = trainDF.groupby('country').search_term.value_counts().unstack(0).plot.bar(rot=360, title="Article Frequency")
ax.set_ylabel("# Articles")
ax.set_xlabel("Search Term")

trainDF.groupby(['country','search_term']).size()

"""# **US vs. GB Overall**

## US vs. GB Data Prep
"""

#Creating empty lists that will be appended to from the loop
#Empty term label
termLabel=[]
#Empty country label
countryLabel=[]
#Empty title label
titleList=[]
#Empty urlAdd list
urlAddrList=[]
#Empty provider list
providerLabel=[]
#Empty date published list
datePublishedList = []
#Empty description content list
descList = []

#Opening the raw review file and reading the first line which are the headers
with open('/content/gdrive/MyDrive/train_data_group_3_final.csv','r') as FILE:
    FILE.readline()
    #Now that the file pointer has skipped the header row the following loop will append the review text into the corresponding empty lists
    for row in FILE:
        #Splitting the label from the review elements
        term, country, title, url, provider, published, description =row.split(",", 6)
        #Appending
        descList.append(description)
        #Appending
        termLabel.append(term)
        #Appending
        countryLabel.append(country)
        #Appending
        titleList.append(title)
        #Appending
        urlAddrList.append(url)
        #Appending
        providerLabel.append(provider)
        #Appending
        datePublishedList.append(published)

#Code from https://scikit-learn.org/stable/modules/feature_extraction.html
#6.2.3.10. Customizing the vectorizer classes

class LemmaTokenizer:
     def __init__(self):
         self.wnl = WordNetLemmatizer()
     def __call__(self, doc):
         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]
     
#Defining the CountVectorizer using the input = 'content' using the 'word' analyzer
CV=CountVectorizer(input='content',
                        analyzer = 'word',
                        stop_words='english',
                        lowercase = True)

#Defining the TfidfVectorizer using the input = 'content' using the 'word' analyzer
TF=TfidfVectorizer(input='content',
                        analyzer = 'word',
                        use_idf=True,
                        stop_words='english',
                        lowercase = True)                  

#Defining the CountVectorizer using the input = 'content' using ngrams                
CV_gram12 = CountVectorizer(encoding='latin-1', 
                                          ngram_range=(1,2), 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)

#Defining the CountVectorizer using the input = 'content' using boolean values 
CV_boolean = CountVectorizer(encoding='latin-1',
                                          binary=True, 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)


#Defining the CountVectorizer using the input = 'content' using the 'word' analyzer and boolean values 
CV_boolean_lem = CountVectorizer(encoding='latin-1',
                                           tokenizer=LemmaTokenizer(),
                                           analyzer = 'word',
                                           binary=True,
                                           min_df=5, 
                                           stop_words='english',
                                           lowercase = True)

#Defining the CountVectorizer using the input = 'content' using ngrams  and boolean values
CV_gram12_boolean = CountVectorizer(encoding='latin-1',
                                          binary=True,
                                          ngram_range=(1,2), 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)

#Transforming the content, using the description list, to a document term matrix array
X_CV=CV.fit_transform(descList)
X_TF=TF.fit_transform(descList)
X_CV_gram12=CV_gram12.fit_transform(descList)
X_CV_boolean=CV_boolean.fit_transform(descList)
X_CV_boolean_lem=CV_boolean_lem.fit_transform(descList)
X_CV_gram12_boolean=CV_gram12_boolean.fit_transform(descList)

#Setting the feature names to a columns list
ColNamesCV=CV.get_feature_names()
ColNamesTF=TF.get_feature_names()
ColNamesCV_gram12=CV_gram12.get_feature_names()
ColNamesCV_boolean=CV_boolean.get_feature_names()
ColNamestCV_boolean_lem=CV_boolean_lem.get_feature_names()
ColNamesCV_gram12_boolean=CV_gram12_boolean.get_feature_names()

#Creating the dataframes
country_DF_CV = pd.DataFrame(X_CV.toarray(), columns=ColNamesCV)
country_DF_TF = pd.DataFrame(X_TF.toarray(), columns=ColNamesTF)
country_DF_CV_gram12 = pd.DataFrame(X_CV_gram12.toarray(), columns=ColNamesCV_gram12)
country_DF_CV_boolean = pd.DataFrame(X_CV_boolean.toarray(), columns=ColNamesCV_boolean)
country_DF_CV_boolean_lem = pd.DataFrame(X_CV_boolean_lem.toarray(), columns=ColNamestCV_boolean_lem)
country_DF_CV_gram12_boolean = pd.DataFrame(X_CV_gram12_boolean.toarray(), columns=ColNamesCV_gram12_boolean)

#Getting the sums of each vector in the array 
cv_count = X_CV.toarray().sum(axis=0)

tokens_CV = CV.get_feature_names()

#Merging the token names and their frequencies of the Count_Vectorizer array into a dataframe
token_count_CV = pd.DataFrame(cv_count, index=tokens_CV, columns=['Counts'])

#Sorting the dataframe by frequency count highest to lowest
token_count_CV.sort_values(by ='Counts', ascending = False).head(20)

#Getting the sums of each vector in the array 
tf_count = X_TF.toarray().sum(axis=0)

tokens_TF = TF.get_feature_names()

#Merging the token names and their frequencies of the Count_Vectorizer array into a dataframe
token_count_TF = pd.DataFrame(tf_count, index=tokens_TF, columns=['Normalized Frequncy Totals'])

#Sorting the dataframe by frequency count highest to lowest
token_count_TF.sort_values(by ='Normalized Frequncy Totals', ascending = False).head(20)

#Creating a function that will return a result of TRUE if digits are present in a string
def Logical_Numbers_Present(anyString):
    return any(char.isdigit() for char in anyString)

#creating a loop to iterate through the dataframes and droping numbers and words that have less than 3 letters

for nextcol in country_DF_CV.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV=country_DF_CV.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV=country_DF_CV.drop([nextcol], axis=1)

for nextcol in country_DF_TF.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_TF=country_DF_TF.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_TF=country_DF_TF.drop([nextcol], axis=1)

for nextcol in country_DF_CV_gram12.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_gram12=country_DF_CV_gram12.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_gram12=country_DF_CV_gram12.drop([nextcol], axis=1)

for nextcol in country_DF_CV_boolean.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_boolean=country_DF_CV_boolean.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_boolean=country_DF_CV_boolean.drop([nextcol], axis=1)

for nextcol in country_DF_CV_boolean_lem.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_boolean_lem=country_DF_CV_boolean_lem.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_boolean_lem=country_DF_CV_boolean_lem.drop([nextcol], axis=1)

for nextcol in country_DF_CV_gram12_boolean.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_gram12_boolean=country_DF_CV_gram12_boolean.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_gram12_boolean=country_DF_CV_gram12_boolean.drop([nextcol], axis=1)

#inserting the country label list into the dataframes
country_DF_CV.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_TF.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_gram12.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_boolean.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_boolean_lem.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_gram12_boolean.insert(loc=0, column='LABEL', value=countryLabel)

def show_most_informative_features(vectorizer, clf, n=20):
    feature_names = vectorizer.get_feature_names()
    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
    for (coef_1, fn_1), (coef_2, fn_2) in top:
        print("\t%.4f\t%-15s\t\t%.4f\t%-15s" % (coef_1, fn_1, coef_2, fn_2))

def show_top20(classifier, vectorizer):
    neg_class_prob_sorted = classifier.feature_log_prob_[0, :].argsort()
    pos_class_prob_sorted = classifier.feature_log_prob_[1, :].argsort()
    print("20 most important words for choosing GB:")
    print(np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[-20:]))
    print("20 most important words for choosing US:")
    print(np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[-20:]))

rd.seed(1234)

#using sklearn package to set up a test & train set for each of the datasets
train1, test1 = train_test_split(country_DF_CV, test_size=0.2, random_state=1)
print(train1.shape, test1.shape)
train2, test2 = train_test_split(country_DF_TF, test_size=0.2, random_state=1)
print(train2.shape, test2.shape)
train3, test3 = train_test_split(country_DF_CV_gram12, test_size=0.2, random_state=1)
print(train3.shape, test3.shape)
train4, test4 = train_test_split(country_DF_CV_boolean, test_size=0.2, random_state=1)
print(train4.shape, test4.shape)
train5, test5 = train_test_split(country_DF_CV_boolean_lem, test_size=0.2, random_state=1)
print(train5.shape, test5.shape)
train6, test6 = train_test_split(country_DF_CV_gram12_boolean, test_size=0.2, random_state=1)
print(train6.shape, test6.shape)

#################
#   Test Set    #
#################

#Isolating the labels from the test sets into their own dataframe
test_CV_Labels=test1["LABEL"]
#finding the category frequency in the test set
unique, counts = np.unique(test_CV_Labels, return_counts=True)
print(np.asarray((unique, counts)))

test_TF_Labels=test2["LABEL"]
#finding the category frequency in the test set
unique, counts = np.unique(test_TF_Labels, return_counts=True)
print(np.asarray((unique, counts)))

test_CV_gram12_Labels=test3["LABEL"]
#finding the category frequency in the test set
unique, counts = np.unique(test_CV_gram12_Labels, return_counts=True)
print(np.asarray((unique, counts)))

test_CV_boolean_Labels=test4["LABEL"]
#finding the category frequency in the test set
unique, counts = np.unique(test_CV_boolean_Labels, return_counts=True)
print(np.asarray((unique, counts)))

test_CV_boolean_lem_Labels=test5["LABEL"]
#finding the category frequency in the test set
unique, counts = np.unique(test_CV_boolean_lem_Labels, return_counts=True)
print(np.asarray((unique, counts)))

test_CV_gram12_boolean_Labels=test6["LABEL"]
#finding the category frequency in the test set
unique, counts = np.unique(test_CV_gram12_boolean_Labels, return_counts=True)
print(np.asarray((unique, counts)))

#Isolating the content from the test sets by dropping the labels
CV_Test = test1.drop(["LABEL"], axis=1)
TF_Test = test2.drop(["LABEL"], axis=1)
CV_gram12_Test = test3.drop(["LABEL"], axis=1)
CV_boolean_Test = test4.drop(["LABEL"], axis=1)
CV_boolean_lem_Test = test5.drop(["LABEL"], axis=1)
CV_gram12_boolean_Test = test6.drop(["LABEL"], axis=1)

##################
#   Train Set    #
##################

#Isolating the labels from the train sets into their own dataframe

train_CV_Labels=train1["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_TF_Labels=train2["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_TF_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_gram12_Labels=train3["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_gram12_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_boolean_Labels=train4["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_boolean_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_boolean_lem_Labels=train5["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_boolean_lem_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_gram12_boolean_Labels=train6["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_gram12_boolean_Labels, return_counts=True)
print(np.asarray((unique, counts)))

#Isolating the content from the train sets by dropping the labels
CV_Train = train1.drop(["LABEL"], axis=1)
TF_Train = train2.drop(["LABEL"], axis=1)
CV_gram12_Train = train3.drop(["LABEL"], axis=1)
CV_boolean_Train = train4.drop(["LABEL"], axis=1)
CV_boolean_lem_Train = train5.drop(["LABEL"], axis=1)
CV_gram12_boolean_Train = train6.drop(["LABEL"], axis=1)

"""## US vs. GB Data Naive Bayes"""

####################################################################
########################### Naive Bayes ############################
####################################################################
#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit
#Declaring the classifier
MyModelNB= MultinomialNB()

################################################################################

#Fitting the classifier 
NB_CV=MyModelNB.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV = NB_CV.predict(CV_Test)
#Array of the target probabilities
#print(np.round(NB_CV.predict_proba(CV_Test),2))

#Confusion Matrix
cnf_matrix_CV = confusion_matrix(test_CV_Labels, Prediction_CV)
print("\nThe NB_CV confusion matrix is:")
print(cnf_matrix_CV)
print("\nThe NB_CV train accuracy is:")
NB_CV_train_score = NB_CV.score(CV_Train, train_CV_Labels)
print(NB_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV = cross_val_score(NB_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV.mean(), scores_CV.std() * 2))
scores_CV_Mean = scores_CV.mean()
print("\nThe NB_CV test accuracy is:")
print(NB_CV.score(CV_Test, test_CV_Labels))
score_test_NB_CV = NB_CV.score(CV_Test, test_CV_Labels)
print('\n')
show_top20(NB_CV, CV)
print('\n')
print("CV Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV, NB_CV)
print('\n')
disp = plot_confusion_matrix(NB_CV, CV_Test, test_CV_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################

#Fitting the classifier 
NB_TF=MyModelNB.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF = NB_TF.predict(TF_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(NB_TF.predict_proba(TF_Test),2))

#Confusion Matrix
cnf_matrix_TF = confusion_matrix(test_TF_Labels, Prediction_TF)
print("\nThe NB_TF confusion matrix is:")
print(cnf_matrix_TF)
print("\nThe NB_TF train accuracy is:")
NB_TF_train_score = NB_TF.score(TF_Train, train_TF_Labels)
print(NB_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF = cross_val_score(NB_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF.mean(), scores_TF.std() * 2))
scores_TF_Mean = scores_TF.mean()
print("\nThe NB_TF test accuracy is:")
print(NB_TF.score(TF_Test, test_TF_Labels))
score_test_NB_TF = NB_TF.score(TF_Test, test_TF_Labels)
print('\n')
show_top20(NB_TF, TF)
print('\n')
print("TF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(TF, NB_TF)
print('\n')
disp = plot_confusion_matrix(NB_TF, TF_Test, test_TF_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################

#Fitting the classifier 
NB_CV_gram12=MyModelNB.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12 = NB_CV_gram12.predict(CV_gram12_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(NB_CV_gram12.predict_proba(CV_gram12_Test),2))

#Confusion Matrix
cnf_matrix_CV_gram12 = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12)
print("\nThe NB_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12)
print("\nThe NB_CV_gram12 train accuracy is:")
NB_CV_gram12_train_score = NB_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(NB_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12 = cross_val_score(NB_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12.mean(), scores_CV_gram12.std() * 2))
scores_CV_gram12_Mean = scores_CV_gram12.mean()
print("\nThe NB_CV_gram12 test accuracy is:")
print(NB_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_NB_CV_gram12 = NB_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)
print('\n')
show_top20(NB_CV_gram12, CV_gram12)
print('\n')
print("CV NGRAM Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_gram12, NB_CV_gram12)
print('\n')
disp = plot_confusion_matrix(NB_CV_gram12, CV_gram12_Test, test_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################
###                        Naive Bayes Bernoulli                             ###
################################################################################

bernoulliNB = BernoulliNB()

#Fitting the classifier 
bernoulliNB_CV_boolean_lem = bernoulliNB.fit(CV_boolean_lem_Train, train_CV_boolean_lem_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_boolean_lem = bernoulliNB_CV_boolean_lem.predict(CV_boolean_lem_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_boolean_lem.predict_proba(CV_boolean_lem_Test),2))

#Confusion Matrix
cnf_matrix_tfidf_boolean = confusion_matrix(test_CV_boolean_lem_Labels, Prediction_CV_boolean_lem)
print("\nThe bernoulliNB_CV_boolean_lem confusion matrix is:")
print(cnf_matrix_tfidf_boolean)
print("\nThe bernoulliNB_CV_boolean_lem train accuracy is:")
bernoulliNB_CV_boolean_lem_train_score = bernoulliNB_CV_boolean_lem.score(CV_boolean_lem_Train, train_CV_boolean_lem_Labels)
print(bernoulliNB_CV_boolean_lem_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_boolean_lem = cross_val_score(bernoulliNB_CV_boolean_lem, CV_boolean_lem_Train, train_CV_boolean_lem_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_boolean_lem Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_boolean_lem.mean(), scores_CV_boolean_lem.std() * 2))
scores_CV_boolean_lem_Mean = scores_CV_boolean_lem.mean()
print("\nThe bernoulliNB_CV_boolean_lem test accuracy is:")
print(bernoulliNB_CV_boolean_lem.score(CV_boolean_lem_Test, test_CV_boolean_lem_Labels))
score_test_bernoulliNB_CV_boolean_lem = bernoulliNB_CV_boolean_lem.score(CV_boolean_lem_Test, test_CV_boolean_lem_Labels)
print('\n')
show_top20(NB_CV_gram12, CV_gram12)
print('\n')
print("CV with Leammatization Bernoulli Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_boolean_lem, bernoulliNB_CV_boolean_lem)
print('\n')
disp = plot_confusion_matrix(bernoulliNB_CV_boolean_lem, CV_boolean_lem_Test, test_CV_boolean_lem_Labels, cmap = plt.cm.Blues, values_format = '')
#########################################################################################################

#Fitting the classifier 
bernoulliNB_CV_boolean = bernoulliNB.fit(CV_boolean_Train , train_CV_boolean_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_boolean = bernoulliNB_CV_boolean.predict(CV_boolean_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_boolean.predict_proba(CV_boolean_Test),2))

#Confusion Matrix
cnf_matrix_CV_boolean = confusion_matrix(test_CV_boolean_Labels, Prediction_CV_boolean)
print("\nThe bernoulliNB_CV_boolean confusion matrix is:")
print(cnf_matrix_CV_boolean)
print("\nThe bernoulliNB_CV_boolean train accuracy is:")
bernoulliNB_CV_boolean_train_score = bernoulliNB_CV_boolean.score(CV_boolean_Train, train_CV_boolean_Labels)
print(bernoulliNB_CV_boolean_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_boolean = cross_val_score(bernoulliNB_CV_boolean, CV_boolean_Train, train_CV_boolean_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_boolean Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_boolean.mean(), scores_CV_boolean.std() * 2))
scores_CV_boolean_Mean = scores_CV_boolean.mean()
print("\nThe bernoulliNB_CV_boolean test accuracy is:")
print(bernoulliNB_CV_boolean.score(CV_boolean_Test, test_CV_boolean_Labels))
score_test_bernoulliNB_CV_boolean = bernoulliNB_CV_boolean.score(CV_boolean_Test, test_CV_boolean_Labels)
print('\n')
show_top20(NB_CV_gram12, CV_gram12)
print('\n')
print("CV Bernoulli Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_boolean, bernoulliNB_CV_boolean)
print('\n')

disp = plot_confusion_matrix(bernoulliNB_CV_boolean, CV_boolean_Test, test_CV_boolean_Labels, cmap = plt.cm.Blues, values_format = '')
#########################################################################################################

#Fitting the classifier 
bernoulliNB_CV_gram12_boolean = bernoulliNB.fit(CV_gram12_boolean_Train , train_CV_gram12_boolean_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_boolean = bernoulliNB_CV_gram12_boolean.predict(CV_gram12_boolean_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_gram12_boolean.predict_proba(CV_gram12_boolean_Sentiment_Test),2))

#Confusion Matrix
cnf_matrix_CV_gram12_boolean = confusion_matrix(test_CV_gram12_boolean_Labels, Prediction_CV_gram12_boolean)
print("\nThe bernoulliNB_CV_gram12_boolean confusion matrix is:")
print(cnf_matrix_CV_gram12_boolean)
print("\nThe bernoulliNB_CV_gram12_boolean train accuracy is:")
bernoulliNB_CV_gram12_boolean_train_score = bernoulliNB_CV_gram12_boolean.score(CV_gram12_boolean_Train, train_CV_gram12_boolean_Labels)
print(bernoulliNB_CV_gram12_boolean_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_boolean = cross_val_score(bernoulliNB_CV_gram12_boolean, CV_gram12_boolean_Train, train_CV_gram12_boolean_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_gram12_boolean Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_boolean.mean(), scores_CV_gram12_boolean.std() * 2))
scores_CV_gram12_boolean_Mean = scores_CV_gram12_boolean.mean()
print("\nThe bernoulliNB_CV_gram12_boolean test accuracy is:")
print(bernoulliNB_CV_gram12_boolean.score(CV_gram12_boolean_Test, test_CV_gram12_boolean_Labels))
score_test_bernoulliNB_CV_gram12_boolean = bernoulliNB_CV_gram12_boolean.score(CV_gram12_boolean_Test, test_CV_gram12_boolean_Labels)
print('\n')
show_top20(NB_CV_gram12, CV_gram12)
print('\n')
print("CV NGRAM Bernoulli Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_gram12_boolean, bernoulliNB_CV_gram12_boolean)

disp = plot_confusion_matrix(bernoulliNB_CV_gram12_boolean, CV_gram12_boolean_Test, test_CV_gram12_boolean_Labels, cmap = plt.cm.Blues, values_format = '')
#########################################################################################################

import sys
np.set_printoptions(threshold=sys.maxsize)

#I learned how to perform a grid search for hyperparameter tuning at:
#https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/

#creating a function that takes the train set and kernal type and produces the best combo
def hyper_tune_svm(train_X, train_y, kernal):
    #Range of parameter
    param_grid = {'C': [0.1, 1, 10, 100, 1000],  
                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 
                  'kernel': [kernal]}  
     
    #Creating the model 
    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) 
      
    #Fitting 
    grid.fit(train_X, train_y) 
    
    #printing results
    print(grid.best_params_)

"""## US vs. GB Data SVM"""

####################################################################
###########################     SVM     ############################
####################################################################

#######################
###   Linear SVM    ###
#######################
#######################
##        CV        ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=.1)

################################################################################

#Fitting the classifier 
SVM_CV = SVM_Model1.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV, CV_Test, test_CV_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Linear SVM    ###
#######################
#######################
##       TFIDF      ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=5)

#Fitting the classifier 
SVM_TF = SVM_Model1.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_TF, TF_Test, test_TF_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Linear SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=.1)

#Fitting the classifier 
SVM_CV_gram12=SVM_Model1.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV_gram12, CV_gram12_Test, test_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Radial SVM    ###
#######################
#######################
##         CV       ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=100, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV = SVM_Model2.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV_gram12, CV_gram12_Test, test_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################

#######################
###   Radial SVM    ###
#######################
#######################
##       TFIDF      ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=100, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_TF = SVM_Model2.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

#######################
###   Radial SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=100, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model2.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

##### POLYNOMIAL SVM ######

#######################
###     Poly SVM    ###
#######################
#######################
###        CV       ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV = SVM_Model3.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

disp = plot_confusion_matrix(SVM_CV, CV_Test, test_CV_Labels, cmap = plt.cm.Blues, values_format = '')

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))

#######################
###     Poly SVM    ###
#######################
#######################
###      TFIDF      ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_TF = SVM_Model3.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))

#######################
###     Poly SVM    ###
#######################
#######################
###      NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model3.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

"""# **Racing**

Kyle

### Racing Data Prep
"""

#Creating empty lists that will be appended to from the loop
#Empty term label
termLabel=[]
#Empty country label
countryLabel=[]
#Empty title label
titleList=[]
#Empty urlAdd list
urlAddrList=[]
#Empty provider list
providerLabel=[]
#Empty date published list
datePublishedList = []
#Empty description content list
descList = []

#Opening the raw review file and reading the first line which are the headers
with open('/content/gdrive/MyDrive/train_data_group_3_final.csv','r') as FILE:
    FILE.readline()
    #Now that the file pointer has skipped the header row the following loop will append the review text into the corresponding empty lists
    for row in FILE:
        #Splitting the label from the review elements
        term, country, title, url, provider, published, description =row.split(",", 6)
        if term == "racing":
        #Appending
          descList.append(description)
        #Appending
          termLabel.append(term)
        #Appending
          countryLabel.append(country)
        #Appending
          titleList.append(title)
        #Appending
          urlAddrList.append(url)
        #Appending
          providerLabel.append(provider)
        #Appending
          datePublishedList.append(published)

#Code from https://scikit-learn.org/stable/modules/feature_extraction.html
#6.2.3.10. Customizing the vectorizer classes

class LemmaTokenizer:
     def __init__(self):
         self.wnl = WordNetLemmatizer()
     def __call__(self, doc):
         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]
     
#Defining the CountVectorizer using the input = 'content' using the 'word' analyzer
CV=CountVectorizer(input='content',
                        analyzer = 'word',
                        stop_words='english',
                        lowercase = True)

#Defining the TfidfVectorizer using the input = 'content' using the 'word' analyzer
TF=TfidfVectorizer(input='content',
                        analyzer = 'word',
                        use_idf=True,
                        stop_words='english',
                        lowercase = True)                  

#Defining the CountVectorizer using the input = 'content' using ngrams                
CV_gram12 = CountVectorizer(encoding='latin-1', 
                                          ngram_range=(1,2), 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)

#Defining the CountVectorizer using the input = 'content' using boolean values 
CV_boolean = CountVectorizer(encoding='latin-1',
                                          binary=True, 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)


#Defining the CountVectorizer using the input = 'content' using the 'word' analyzer and boolean values 
CV_boolean_lem = CountVectorizer(encoding='latin-1',
                                           tokenizer=LemmaTokenizer(),
                                           analyzer = 'word',
                                           binary=True,
                                           min_df=5, 
                                           stop_words='english',
                                           lowercase = True)

#Defining the CountVectorizer using the input = 'content' using ngrams  and boolean values
CV_gram12_boolean = CountVectorizer(encoding='latin-1',
                                          binary=True,
                                          ngram_range=(1,2), 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)

#Transforming the content, using the description list, to a document term matrix array
X_CV=CV.fit_transform(descList)
X_TF=TF.fit_transform(descList)
X_CV_gram12=CV_gram12.fit_transform(descList)
X_CV_boolean=CV_boolean.fit_transform(descList)
X_CV_boolean_lem=CV_boolean_lem.fit_transform(descList)
X_CV_gram12_boolean=CV_gram12_boolean.fit_transform(descList)

#Setting the feature names to a columns list
ColNamesCV=CV.get_feature_names()
ColNamesTF=TF.get_feature_names()
ColNamesCV_gram12=CV_gram12.get_feature_names()
ColNamesCV_boolean=CV_boolean.get_feature_names()
ColNamestCV_boolean_lem=CV_boolean_lem.get_feature_names()
ColNamesCV_gram12_boolean=CV_gram12_boolean.get_feature_names()

#Creating the dataframes
country_DF_CV = pd.DataFrame(X_CV.toarray(), columns=ColNamesCV)
country_DF_TF = pd.DataFrame(X_TF.toarray(), columns=ColNamesTF)
country_DF_CV_gram12 = pd.DataFrame(X_CV_gram12.toarray(), columns=ColNamesCV_gram12)
country_DF_CV_boolean = pd.DataFrame(X_CV_boolean.toarray(), columns=ColNamesCV_boolean)
country_DF_CV_boolean_lem = pd.DataFrame(X_CV_boolean_lem.toarray(), columns=ColNamestCV_boolean_lem)
country_DF_CV_gram12_boolean = pd.DataFrame(X_CV_gram12_boolean.toarray(), columns=ColNamesCV_gram12_boolean)

#Creating a function that will return a result of TRUE if digits are present in a string
def Logical_Numbers_Present(anyString):
    return any(char.isdigit() for char in anyString)

#creating a loop to iterate through the dataframes and droping numbers and words that have less than 3 letters

for nextcol in country_DF_CV.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV=country_DF_CV.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV=country_DF_CV.drop([nextcol], axis=1)

for nextcol in country_DF_TF.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_TF=country_DF_TF.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_TF=country_DF_TF.drop([nextcol], axis=1)

for nextcol in country_DF_CV_gram12.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_gram12=country_DF_CV_gram12.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_gram12=country_DF_CV_gram12.drop([nextcol], axis=1)

for nextcol in country_DF_CV_boolean.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_boolean=country_DF_CV_boolean.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_boolean=country_DF_CV_boolean.drop([nextcol], axis=1)

for nextcol in country_DF_CV_boolean_lem.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_boolean_lem=country_DF_CV_boolean_lem.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_boolean_lem=country_DF_CV_boolean_lem.drop([nextcol], axis=1)

for nextcol in country_DF_CV_gram12_boolean.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        country_DF_CV_gram12_boolean=country_DF_CV_gram12_boolean.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        country_DF_CV_gram12_boolean=country_DF_CV_gram12_boolean.drop([nextcol], axis=1)

#inserting the country label list into the dataframes
country_DF_CV.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_TF.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_gram12.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_boolean.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_boolean_lem.insert(loc=0, column='LABEL', value=countryLabel)
country_DF_CV_gram12_boolean.insert(loc=0, column='LABEL', value=countryLabel)

rd.seed(1234)

#using sklearn package to set up a test & train set for each of the datasets
train1, test1 = train_test_split(country_DF_CV, test_size=0.3)
print(train1.shape, test1.shape)
train2, test2 = train_test_split(country_DF_TF, test_size=0.3)
print(train2.shape, test2.shape)
train3, test3 = train_test_split(country_DF_CV_gram12, test_size=0.3)
print(train3.shape, test3.shape)
train4, test4 = train_test_split(country_DF_CV_boolean, test_size=0.3)
print(train4.shape, test4.shape)
train5, test5 = train_test_split(country_DF_CV_boolean_lem, test_size=0.3)
print(train5.shape, test5.shape)
train6, test6 = train_test_split(country_DF_CV_gram12_boolean, test_size=0.3)
print(train6.shape, test6.shape)

#################
#   Test Set    #
#################

#Isolating the labels from the test sets into their own dataframe
test_CV_Labels=test1["LABEL"]
test_TF_Labels=test2["LABEL"]
test_CV_gram12_Labels=test3["LABEL"]
test_CV_boolean_Labels=test4["LABEL"]
test_CV_boolean_lem_Labels=test5["LABEL"]
test_CV_gram12_boolean_Labels=test6["LABEL"]

#Isolating the content from the test sets by dropping the labels
CV_Test = test1.drop(["LABEL"], axis=1)
TF_Test = test2.drop(["LABEL"], axis=1)
CV_gram12_Test = test3.drop(["LABEL"], axis=1)
CV_boolean_Test = test4.drop(["LABEL"], axis=1)
CV_boolean_lem_Test = test5.drop(["LABEL"], axis=1)
CV_gram12_boolean_Test = test6.drop(["LABEL"], axis=1)

##################
#   Train Set    #
##################

#Isolating the labels from the train sets into their own dataframe

train_CV_Labels=train1["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_TF_Labels=train2["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_TF_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_gram12_Labels=train3["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_gram12_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_boolean_Labels=train4["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_boolean_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_boolean_lem_Labels=train5["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_boolean_lem_Labels, return_counts=True)
print(np.asarray((unique, counts)))

train_CV_gram12_boolean_Labels=train6["LABEL"]
#finding the category frequency in the training set
unique, counts = np.unique(train_CV_gram12_boolean_Labels, return_counts=True)
print(np.asarray((unique, counts)))

#Isolating the content from the train sets by dropping the labels
CV_Train = train1.drop(["LABEL"], axis=1)
TF_Train = train2.drop(["LABEL"], axis=1)
CV_gram12_Train = train3.drop(["LABEL"], axis=1)
CV_boolean_Train = train4.drop(["LABEL"], axis=1)
CV_boolean_lem_Train = train5.drop(["LABEL"], axis=1)
CV_gram12_boolean_Train = train6.drop(["LABEL"], axis=1)

def show_top20(classifier, vectorizer):
    neg_class_prob_sorted = classifier.feature_log_prob_[0, :].argsort()
    pos_class_prob_sorted = classifier.feature_log_prob_[1, :].argsort()
    print("20 most important words for choosing GB:")
    print(np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[-20:]))
    print("20 most important words for choosing US:")
    print(np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[-20:]))

"""### Racing Naive Bayes"""

####################################################################
########################### Naive Bayes ############################
####################################################################
#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit
#Declaring the classifier
MyModelNB= MultinomialNB()

################################################################################

#Fitting the classifier 
NB_CV=MyModelNB.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV = NB_CV.predict(CV_Test)
#Array of the target probabilities
#print(np.round(NB_CV.predict_proba(CV_Test),2))

#Confusion Matrix
cnf_matrix_CV = confusion_matrix(test_CV_Labels, Prediction_CV)
print("\nThe NB_CV confusion matrix is:")
print(cnf_matrix_CV)
print("\nThe NB_CV train accuracy is:")
NB_CV_train_score = NB_CV.score(CV_Train, train_CV_Labels)
print(NB_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV = cross_val_score(NB_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV.mean(), scores_CV.std() * 2))
scores_CV_Mean = scores_CV.mean()
print("\nThe NB_CV test accuracy is:")
print(NB_CV.score(CV_Test, test_CV_Labels))
score_test_NB_CV = NB_CV.score(CV_Test, test_CV_Labels)

show_top20(MyModelNB, CV)

################################################################################

#Fitting the classifier 
NB_TF=MyModelNB.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF = NB_TF.predict(TF_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(NB_TF.predict_proba(TF_Test),2))

#Confusion Matrix
cnf_matrix_TF = confusion_matrix(test_TF_Labels, Prediction_TF)
print("\nThe NB_TF confusion matrix is:")
print(cnf_matrix_TF)
print("\nThe NB_TF train accuracy is:")
NB_TF_train_score = NB_TF.score(TF_Train, train_TF_Labels)
print(NB_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF = cross_val_score(NB_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF.mean(), scores_TF.std() * 2))
scores_TF_Mean = scores_TF.mean()
print("\nThe NB_TF test accuracy is:")
print(NB_TF.score(TF_Test, test_TF_Labels))
score_test_NB_TF = NB_TF.score(TF_Test, test_TF_Labels)

show_top20(MyModelNB, TF)

################################################################################

#Fitting the classifier 
NB_CV_gram12=MyModelNB.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12 = NB_CV_gram12.predict(CV_gram12_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(NB_CV_gram12.predict_proba(CV_gram12_Test),2))

#Confusion Matrix
cnf_matrix_CV_gram12 = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12)
print("\nThe NB_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12)
print("\nThe NB_CV_gram12 train accuracy is:")
NB_CV_gram12_train_score = NB_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(NB_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12 = cross_val_score(NB_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12.mean(), scores_CV_gram12.std() * 2))
scores_CV_gram12_Mean = scores_CV_gram12.mean()
print("\nThe NB_CV_gram12 test accuracy is:")
print(NB_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_NB_CV_gram12 = NB_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

show_top20(MyModelNB, CV_gram12)

################################################################################
###                        Naive Bayes Bernoulli                             ###
################################################################################

bernoulliNB = BernoulliNB()

#Fitting the classifier 
bernoulliNB_CV_boolean_lem = bernoulliNB.fit(CV_boolean_lem_Train, train_CV_boolean_lem_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_boolean_lem = bernoulliNB_CV_boolean_lem.predict(CV_boolean_lem_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_boolean_lem.predict_proba(CV_boolean_lem_Test),2))

#Confusion Matrix
cnf_matrix_tfidf_boolean = confusion_matrix(test_CV_boolean_lem_Labels, Prediction_CV_boolean_lem)
print("\nThe bernoulliNB_CV_boolean_lem confusion matrix is:")
print(cnf_matrix_tfidf_boolean)
print("\nThe bernoulliNB_CV_boolean_lem train accuracy is:")
bernoulliNB_CV_boolean_lem_train_score = bernoulliNB_CV_boolean_lem.score(CV_boolean_lem_Train, train_CV_boolean_lem_Labels)
print(bernoulliNB_CV_boolean_lem_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_boolean_lem = cross_val_score(bernoulliNB_CV_boolean_lem, CV_boolean_lem_Train, train_CV_boolean_lem_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_boolean_lem Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_boolean_lem.mean(), scores_CV_boolean_lem.std() * 2))
scores_CV_boolean_lem_Mean = scores_CV_boolean_lem.mean()
print("\nThe bernoulliNB_CV_boolean_lem test accuracy is:")
print(bernoulliNB_CV_boolean_lem.score(CV_boolean_lem_Test, test_CV_boolean_lem_Labels))
score_test_bernoulliNB_CV_boolean_lem = bernoulliNB_CV_boolean_lem.score(CV_boolean_lem_Test, test_CV_boolean_lem_Labels)

show_top20(bernoulliNB, CV_boolean_lem)
#########################################################################################################

#Fitting the classifier 
bernoulliNB_CV_boolean = bernoulliNB.fit(CV_boolean_Train , train_CV_boolean_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_boolean = bernoulliNB_CV_boolean.predict(CV_boolean_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_boolean.predict_proba(CV_boolean_Test),2))

#Confusion Matrix
cnf_matrix_CV_boolean = confusion_matrix(test_CV_boolean_Labels, Prediction_CV_boolean)
print("\nThe bernoulliNB_CV_boolean confusion matrix is:")
print(cnf_matrix_CV_boolean)
print("\nThe bernoulliNB_CV_boolean train accuracy is:")
bernoulliNB_CV_boolean_train_score = bernoulliNB_CV_boolean.score(CV_boolean_Train, train_CV_boolean_Labels)
print(bernoulliNB_CV_boolean_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_boolean = cross_val_score(bernoulliNB_CV_boolean, CV_boolean_Train, train_CV_boolean_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_boolean Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_boolean.mean(), scores_CV_boolean.std() * 2))
scores_CV_boolean_Mean = scores_CV_boolean.mean()
print("\nThe bernoulliNB_CV_boolean test accuracy is:")
print(bernoulliNB_CV_boolean.score(CV_boolean_Test, test_CV_boolean_Labels))
score_test_bernoulliNB_CV_boolean = bernoulliNB_CV_boolean.score(CV_boolean_Test, test_CV_boolean_Labels)

show_top20(bernoulliNB, CV_boolean)
#########################################################################################################

#Fitting the classifier 
bernoulliNB_CV_gram12_boolean = bernoulliNB.fit(CV_gram12_boolean_Train , train_CV_gram12_boolean_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_boolean = bernoulliNB_CV_gram12_boolean.predict(CV_gram12_boolean_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_gram12_boolean.predict_proba(CV_gram12_boolean_Sentiment_Test),2))

#Confusion Matrix
cnf_matrix_CV_gram12_boolean = confusion_matrix(test_CV_gram12_boolean_Labels, Prediction_CV_gram12_boolean)
print("\nThe bernoulliNB_CV_gram12_boolean confusion matrix is:")
print(cnf_matrix_CV_gram12_boolean)
print("\nThe bernoulliNB_CV_gram12_boolean train accuracy is:")
bernoulliNB_CV_gram12_boolean_train_score = bernoulliNB_CV_gram12_boolean.score(CV_gram12_boolean_Train, train_CV_gram12_boolean_Labels)
print(bernoulliNB_CV_gram12_boolean_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_boolean = cross_val_score(bernoulliNB_CV_gram12_boolean, CV_gram12_boolean_Train, train_CV_gram12_boolean_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_gram12_boolean Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_boolean.mean(), scores_CV_gram12_boolean.std() * 2))
scores_CV_gram12_boolean_Mean = scores_CV_gram12_boolean.mean()
print("\nThe bernoulliNB_CV_gram12_boolean test accuracy is:")
print(bernoulliNB_CV_gram12_boolean.score(CV_gram12_boolean_Test, test_CV_gram12_boolean_Labels))
score_test_bernoulliNB_CV_gram12_boolean = bernoulliNB_CV_gram12_boolean.score(CV_gram12_boolean_Test, test_CV_gram12_boolean_Labels)

show_top20(bernoulliNB, CV_gram12_boolean)
#########################################################################################################

"""### Racing SVM"""

####################################################################
###########################     SVM     ############################
####################################################################
#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit
#Declaring the classifier
SVM_Model1 =LinearSVC(C=0.1)

################################################################################

#Fitting the classifier 
SVM_CV = SVM_Model1.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))


################################################################################

SVM_Model1 =LinearSVC(C=1)

#Fitting the classifier 
SVM_TF = SVM_Model1.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))


################################################################################

SVM_Model1 =LinearSVC(C=0.1)

#Fitting the classifier 
SVM_CV_gram12=SVM_Model1.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

##### RADIAL SVM ######

SVM_Model2 = sklearn.svm.SVC(C=100, kernel='rbf', degree=3, gamma="auto")

################################################################################

#Fitting the classifier 
SVM_CV = SVM_Model2.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))


################################################################################

SVM_Model2 = sklearn.svm.SVC(C=1000, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_TF = SVM_Model2.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))


################################################################################

SVM_Model2 = sklearn.svm.SVC(C=1000, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model2.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

##### POLYNOMIAL SVM ######

SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

################################################################################

#Fitting the classifier 
SVM_CV = SVM_Model3.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))


################################################################################

SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_TF = SVM_Model3.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))


################################################################################

SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model3.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))



# Subset the data so that we only have racing articles
## print the cols so we can see what we need and what we don't
racing_df = train[train['search_term'] == 'racing']
for col in racing_df.columns:
  print(col)

# Drop unnecessary columns
racing_df = racing_df.drop(['search_term', 'Title', 'urlAddr', 'provider', 'datePublished'], axis = 1)

# Commit the descriptions and the countries to lists for input='content' in countvectorizer
description_list = racing_df.Description.to_list()
country_list = racing_df.country.to_list()

# Establish the countvectorizers
MYCV_B = CountVectorizer(input = 'content', stop_words = "english", binary = True)

MYCV_NORM = CountVectorizer(input = 'content', stop_words = 'english')

MYCV_TFIDF = TfidfVectorizer(input = 'content', stop_words = 'english')

# Define a function that will do all 3 of the CV at once
def vectorize_function(content, labels):
    Bern_sparse_matrix = MYCV_B.fit_transform(content)
    CV_sparse_matrix = MYCV_NORM.fit_transform(content)
    TFIDF_sparse_matrix = MYCV_TFIDF.fit_transform(content)
    
    vocab = MYCV_B.get_feature_names()
    
    df_bern = pd.DataFrame(Bern_sparse_matrix.toarray(), columns = vocab)
    df_norm = pd.DataFrame(CV_sparse_matrix.toarray(), columns = vocab)
    df_TFIDF = pd.DataFrame(TFIDF_sparse_matrix.toarray(), columns = vocab)
    
    df_bern.insert(0, "Country", labels)
    df_norm.insert(0, "Country", labels)
    df_TFIDF.insert(0, "Country", labels)
    
    return(df_bern, df_norm, df_TFIDF)

# Define a function to pull and sort the 20 most positive features and the 20 most negative features for each model
def show_most_informative_features(vectorizer, clf, n=20):
    feature_names = vectorizer.get_feature_names()
    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
    for (coef_1, fn_1), (coef_2, fn_2) in top:
        print("\t%.4f\t%-15s\t\t%.4f\t%-15s" % (coef_1, fn_1, coef_2, fn_2))

# Use the above funciton to return the completed vectorized data frames
racing_bern, racing_norm, racing_tfidf = vectorize_function(description_list, country_list)

# Split into training and testing sets for all 3
BERNX_train, BERNX_test, BERNy_train, BERNy_test = train_test_split(racing_bern.drop('Country', axis = 1), racing_bern.Country, test_size = .2, random_state = 25)
CVX_train, CVX_test, CVy_train, CVy_test = train_test_split(racing_norm.drop('Country', axis = 1), racing_norm.Country, test_size = .2, random_state = 25)
TFX_train, TFX_test, TFy_train, TFy_test = train_test_split(racing_tfidf.drop('Country', axis = 1), racing_tfidf.Country, test_size = .2, random_state = 25)

"""###Racing Naive Bayes (better visuals)"""

### Train Naive Bayes Models

#Store model
BERNNB = BernoulliNB()
#Train Model
BERNNB_model = BERNNB.fit(BERNX_train, BERNy_train)
# Predict the test set
BERN_predict = BERNNB_model.predict(BERNX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(BERNy_test, BERN_predict)

print("Bernoulli Confusion Matrix\n", cnf_matrix)
print("Bernoulli Most Informative Features\n")
show_most_informative_features(MYCV_B, BERNNB_model)
disp = plot_confusion_matrix(BERNNB_model, BERNX_test, BERNy_test, cmap = plt.cm.Blues)
print("Bernoulli Classification Report\n")
print(classification_report(BERNy_test, BERN_predict))



# MNB Model for CV train and test sets
#Store model
CVNB = MultinomialNB()
#Train Model
CVNB_model = CVNB.fit(CVX_train, CVy_train)
# Predict the test set
CVNB_predict = CVNB_model.predict(CVX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(CVy_test, CVNB_predict)

print("Vectorized Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(MYCV_NORM, CVNB_model)
disp = plot_confusion_matrix(CVNB_model, CVX_test, CVy_test, cmap = plt.cm.Blues)

print("Multinomial Naive Bayes Classification Report\n")
print(classification_report(CVy_test, CVNB_predict))


# MNB For TFIDF train and test
#Store model
TFIDFNB = MultinomialNB()
#Train Model
TFIDFNB_model = TFIDFNB.fit(TFX_train, TFy_train)
# Predict the test set
TFIDFNB_predict = TFIDFNB_model.predict(TFX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(TFy_test, TFIDFNB_predict)

print("TFIDF Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("TFIDF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(MYCV_TFIDF, TFIDFNB_model)

disp = plot_confusion_matrix(TFIDFNB_model, TFX_test, TFy_test, cmap = plt.cm.Blues)

print("TFIDF Multinomial Naive Bayes Classificaiton Report\n")
print(classification_report(TFy_test, TFIDFNB_predict))

"""### Racing SVM (better visuals)"""

####################################################################
###########################     SVM     ############################
####################################################################

#######################
###   Linear SVM    ###
#######################
#######################
##        CV        ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=.1)

################################################################################

#Fitting the classifier 
SVM_CV = SVM_Model1.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV, CV_Test, test_CV_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Linear SVM    ###
#######################
#######################
##       TFIDF      ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=5)

#Fitting the classifier 
SVM_TF = SVM_Model1.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_TF, TF_Test, test_TF_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Linear SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=.1)

#Fitting the classifier 
SVM_CV_gram12=SVM_Model1.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV_gram12, CV_gram12_Test, test_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Radial SVM    ###
#######################
#######################
##         CV       ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=100, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV = SVM_Model2.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV, CV_Test, test_CV_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################

#######################
###   Radial SVM    ###
#######################
#######################
##       TFIDF      ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=1000, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_TF = SVM_Model2.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

disp = plot_confusion_matrix(SVM_TF, TF_Test, test_TF_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Radial SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=1000, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model2.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

disp = plot_confusion_matrix(SVM_CV_gram12, CV_gram12_Test, test_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')


# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

##### POLYNOMIAL SVM ######

#######################
###     Poly SVM    ###
#######################
#######################
###        CV       ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV = SVM_Model3.fit(CV_Train, train_CV_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_SVM = SVM_CV.predict(CV_Test)

#Confusion Matrix
cnf_matrix_CV_SVM = confusion_matrix(test_CV_Labels, Prediction_CV_SVM)
print("\nThe SVM_CV confusion matrix is:")
print(cnf_matrix_CV_SVM)
print("\nThe SVM_CV train accuracy is:")
SVM_CV_train_score = SVM_CV.score(CV_Train, train_CV_Labels)
print(SVM_CV_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_SVM = cross_val_score(SVM_CV, CV_Train, train_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_SVM.mean(), scores_CV_SVM.std() * 2))
scores_CV_Mean_SVM = scores_CV_SVM.mean()
print("\nThe SVM_CV test accuracy is:")
print(SVM_CV.score(CV_Test, test_CV_Labels))
score_test_SVM_CV = SVM_CV.score(CV_Test, test_CV_Labels)

disp = plot_confusion_matrix(SVM_CV, CV_Test, test_CV_Labels, cmap = plt.cm.Blues, values_format = '')

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV.get_feature_names(), svm_sorted[-10:]))

#######################
###     Poly SVM    ###
#######################
#######################
###      TFIDF      ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_TF = SVM_Model3.fit(TF_Train, train_TF_Labels)
#Using the model to predict the classification of test set 
Prediction_TF_SVM = SVM_TF.predict(TF_Test)

#Confusion Matrix
cnf_matrix_TF_SVM = confusion_matrix(test_TF_Labels, Prediction_TF_SVM)
print("\nThe SVM_TF confusion matrix is:")
print(cnf_matrix_TF_SVM)
print("\nThe SVM_TF train accuracy is:")
SVM_TF_train_score = SVM_TF.score(TF_Train, train_TF_Labels)
print(SVM_TF_train_score)
#Finding the 10-fold cross-validation on the train set
scores_TF_SVM = cross_val_score(SVM_TF, TF_Train, train_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_TF Train accuracy: %0.2f (+/- %0.2f)' % (scores_TF_SVM.mean(), scores_TF_SVM.std() * 2))
scores_TF_Mean_SVM = scores_TF_SVM.mean()
print("\nThe SVM_TF test accuracy is:")
print(SVM_TF.score(TF_Test, test_TF_Labels))
score_test_SVM_TF = SVM_TF.score(TF_Test, test_TF_Labels)

disp = plot_confusion_matrix(SVM_TF, TF_Test, test_TF_Labels, cmap = plt.cm.Blues, values_format = '')

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(TF.get_feature_names(), svm_sorted[-10:]))

#######################
###     Poly SVM    ###
#######################
#######################
###      NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model3.fit(CV_gram12_Train, train_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(CV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(test_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(CV_gram12_Train, train_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, CV_gram12_Train, train_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(CV_gram12_Test, test_CV_gram12_Labels)

disp = plot_confusion_matrix(SVM_CV_gram12, CV_gram12_Test, test_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

"""#**Football**
### Jack

Try to determine the country of origin of each article about football using naive bayes (multinomial, bernoulli) and SVM based on the description of each article

### Football Data Prep
"""

# Subset the data so that we only have football articles
## print the cols so we can see what we need and what we don't
football_df = train[train['search_term'] == 'football']
for col in football_df.columns:
  print(col)

# Drop unnecessary columns
football_df = football_df.drop(['search_term', 'Title', 'urlAddr', 'provider', 'datePublished'], axis = 1)

# Commit the descriptions and the countries to lists for input='content' in countvectorizer
description_list = football_df.Description.to_list()
country_list = football_df.country.to_list()

# Establish the countvectorizers
MYCV_B = CountVectorizer(input = 'content', stop_words = "english", binary = True)

MYCV_NORM = CountVectorizer(input = 'content', stop_words = 'english')

MYCV_TFIDF = TfidfVectorizer(input = 'content', stop_words = 'english')
           
CV_gram12 = CountVectorizer(encoding='latin-1', ngram_range=(1,2), min_df=5, stop_words='english',lowercase = True)
 
CV_boolean_lem = CountVectorizer(encoding='latin-1',tokenizer=LemmaTokenizer(),analyzer = 'word',binary=True,min_df=5, stop_words='english',lowercase = True)

CV_gram12_boolean = CountVectorizer(encoding='latin-1',binary=True,ngram_range=(1,2), min_df=5, stop_words='english', lowercase = True)

# Define a function that will do all 3 of the CV at once
def vectorize_function(content, labels):
    Bern_sparse_matrix = MYCV_B.fit_transform(content)
    CV_sparse_matrix = MYCV_NORM.fit_transform(content)
    TFIDF_sparse_matrix = MYCV_TFIDF.fit_transform(content)
    CV_gram12_sparse_matrix = CV_gram12.fit_transform(content)
    CV_boolean_lem_sparse_matrix = CV_boolean_lem.fit_transform(content)
    CV_gram12_boolean_sparse_matrix = CV_gram12_boolean.fit_transform(content)

    vocab = MYCV_B.get_feature_names()
    vocabCV_gram12 = CV_gram12.get_feature_names()
    vocabCV_boolean_lem = CV_boolean_lem.get_feature_names()
    vocabCV_gram12_boolean = CV_gram12_boolean.get_feature_names()

    
    df_bern = pd.DataFrame(Bern_sparse_matrix.toarray(), columns = vocab)
    df_norm = pd.DataFrame(CV_sparse_matrix.toarray(), columns = vocab)
    df_TFIDF = pd.DataFrame(TFIDF_sparse_matrix.toarray(), columns = vocab)
    df_gram12 = pd.DataFrame(CV_gram12_sparse_matrix.toarray(), columns = vocabCV_gram12)
    df_boolean_lem = pd.DataFrame(CV_boolean_lem_sparse_matrix.toarray(), columns = vocabCV_boolean_lem)
    df_gram12_boolean = pd.DataFrame(CV_gram12_boolean_sparse_matrix.toarray(), columns = vocabCV_gram12_boolean)
    
    df_bern.insert(0, "Country", labels)
    df_norm.insert(0, "Country", labels)
    df_TFIDF.insert(0, "Country", labels)
    df_gram12.insert(0, "Country", labels)
    df_boolean_lem.insert(0, "Country", labels)
    df_gram12_boolean.insert(0, "Country", labels)
    
    return(df_bern, df_norm, df_TFIDF, df_gram12, df_boolean_lem,df_gram12_boolean)

# Define a function to pull and sort the 20 most positive features and the 20 most negative features for each model
def show_most_informative_features(vectorizer, clf, n=20):
    feature_names = vectorizer.get_feature_names()
    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
    for (coef_1, fn_1), (coef_2, fn_2) in top:
        print("\t%.4f\t%-15s\t\t%.4f\t%-15s" % (coef_1, fn_1, coef_2, fn_2))

# Use the above funciton to return the completed vectorized data frames
foot_bern, foot_norm, foot_tfidf, foot_gram12, foot_boolean_lem, foot_gram12_boolean = vectorize_function(description_list, country_list)

# Split into training and testing sets for all 3
BERNX_train, BERNX_test, BERNy_train, BERNy_test = train_test_split(foot_bern.drop('Country', axis = 1), foot_bern.Country, test_size = .2, random_state = 25)
CVX_train, CVX_test, CVy_train, CVy_test = train_test_split(foot_norm.drop('Country', axis = 1), foot_norm.Country, test_size = .2, random_state = 25)
TFX_train, TFX_test, TFy_train, TFy_test = train_test_split(foot_tfidf.drop('Country', axis = 1), foot_tfidf.Country, test_size = .2, random_state = 25)
gram12X_train, gram12X_test, gram12y_train, gram12y_test = train_test_split(foot_gram12.drop('Country', axis = 1), foot_gram12.Country, test_size = .2, random_state = 25)
boolean_lemX_train, boolean_lemX_test, boolean_lemy_train, boolean_lemy_test = train_test_split(foot_boolean_lem.drop('Country', axis = 1), foot_boolean_lem.Country, test_size = .2, random_state = 25)
gram12_booleanX_train, gram12_booleanX_test, gram12_booleany_train, gram12_booleany_test = train_test_split(foot_gram12_boolean.drop('Country', axis = 1), foot_gram12_boolean.Country, test_size = .2, random_state = 25)

"""###Football Naive Bayes"""

### Train Naive Bayes Models

#Store model
BERNNB = BernoulliNB()
#Train Model
BERNNB_model = BERNNB.fit(BERNX_train, BERNy_train)
# Predict the test set
BERN_predict = BERNNB_model.predict(BERNX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(BERNy_test, BERN_predict)

print("Bernoulli Confusion Matrix\n", cnf_matrix)
print("Bernoulli Most Informative Features\n")
show_most_informative_features(MYCV_B, BERNNB_model)
disp = plot_confusion_matrix(BERNNB_model, BERNX_test, BERNy_test, cmap = plt.cm.Blues)
print("Bernoulli Classification Report\n")
print(classification_report(BERNy_test, BERN_predict))



# MNB Model for CV train and test sets
#Store model
CVNB = MultinomialNB()
#Train Model
CVNB_model = CVNB.fit(CVX_train, CVy_train)
# Predict the test set
CVNB_predict = CVNB_model.predict(CVX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(CVy_test, CVNB_predict)

print("Vectorized Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(MYCV_NORM, CVNB_model)
disp = plot_confusion_matrix(CVNB_model, CVX_test, CVy_test, cmap = plt.cm.Blues)

print("Multinomial Naive Bayes Classification Report\n")
print(classification_report(CVy_test, CVNB_predict))


# MNB For TFIDF train and test
#Store model
TFIDFNB = MultinomialNB()
#Train Model
TFIDFNB_model = TFIDFNB.fit(TFX_train, TFy_train)
# Predict the test set
TFIDFNB_predict = TFIDFNB_model.predict(TFX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(TFy_test, TFIDFNB_predict)

print("TFIDF Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("TFIDF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(MYCV_TFIDF, TFIDFNB_model)

disp = plot_confusion_matrix(TFIDFNB_model, TFX_test, TFy_test, cmap = plt.cm.Blues)

print("TFIDF Multinomial Naive Bayes Classificaiton Report\n")
print(classification_report(TFy_test, TFIDFNB_predict))

# MNB For NGRAM train and test
#Store model
NGRAMNB = MultinomialNB()
#Train Model
NGRAMNB_model = NGRAMNB.fit(gram12X_train, gram12y_train)
# Predict the test set
NGRAMNB_predict = NGRAMNB_model.predict(gram12X_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(gram12y_test, NGRAMNB_predict)

print("TFIDF Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("TFIDF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_gram12, NGRAMNB_model)

disp = plot_confusion_matrix(NGRAMNB_model, gram12X_test, gram12y_test, cmap = plt.cm.Blues)

print("TFIDF Multinomial Naive Bayes Classificaiton Report\n")
print(classification_report(gram12y_test, NGRAMNB_predict))

# BERN with LEMMATIZATION train and test
#Store model
BERN_LEM_NB = MultinomialNB()
#Train Model
BERN_LEM_NB_model = BERN_LEM_NB.fit(boolean_lemX_train, boolean_lemy_train)
# Predict the test set
BERN_LEM_NB_predict = BERN_LEM_NB_model.predict(boolean_lemX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(boolean_lemy_test, BERN_LEM_NB_predict)

print("TFIDF Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("TFIDF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_boolean_lem, BERN_LEM_NB_model)

disp = plot_confusion_matrix(BERN_LEM_NB_model, boolean_lemX_test, boolean_lemy_test, cmap = plt.cm.Blues)

print("TFIDF Multinomial Naive Bayes Classificaiton Report\n")
print(classification_report(boolean_lemy_test, BERN_LEM_NB_predict))

# BERN with NGRAM train and test
#Store model
BERN_NGRAMNB = MultinomialNB()
#Train Model
BERN_NGRAMNB_model = BERN_NGRAMNB.fit(gram12_booleanX_train, gram12_booleany_train)
# Predict the test set
BERN_NGRAMNB_predict = BERN_NGRAMNB.predict(gram12_booleanX_test)
#Build confusion matrix
cnf_matrix = confusion_matrix(gram12_booleany_test, BERN_NGRAMNB_predict)

print("TFIDF Multinomial Naive Bayes Confusion Matrix\n", cnf_matrix)
print("TFIDF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_gram12_boolean, BERN_NGRAMNB_model)

disp = plot_confusion_matrix(BERN_NGRAMNB_model, gram12_booleanX_test, gram12_booleany_test, cmap = plt.cm.Blues)

print("TFIDF Multinomial Naive Bayes Classificaiton Report\n")
print(classification_report(gram12_booleany_test, BERN_NGRAMNB_predict))

# Cross Validation and Training Accuracies 
print('Bernoulli NB')
print('The training score is:')
train_score = BERNNB_model.score(BERNX_train, BERNy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(BERNNB_model, BERNX_train, BERNy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(BERNNB_model.score(BERNX_test, BERNy_test))
score_test_SVM_CV = BERNNB_model.score(BERNX_test, BERNy_test)


print('\n')

print('Term Freq MNB')
print('The training score is:')
train_score = CVNB_model.score(CVX_train, CVy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(CVNB_model, CVX_train, CVy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(CVNB_model.score(CVX_test, CVy_test))
score_test_SVM_CV = CVNB_model.score(CVX_test, CVy_test)

print('\n')

print('TFIDF MNB')
print('The training score is:')
train_score = TFIDFNB_model.score(TFX_train, TFy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(TFIDFNB_model, TFX_train, TFy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(TFIDFNB_model.score(TFX_test, TFy_test))
score_test_SVM_CV = TFIDFNB_model.score(TFX_test, TFy_test)

print('\n')

print('CV NGRAM MNB')
print('The training score is:')
train_score = NGRAMNB.score(gram12X_train, gram12y_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(NGRAMNB, gram12X_train, gram12y_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(NGRAMNB.score(gram12X_test, gram12y_test))
score_test_SVM_CV = NGRAMNB.score(gram12X_test, gram12y_test)

print('\n')

print('BERN CV LEM MNB')
print('The training score is:')
train_score = BERN_LEM_NB.score(boolean_lemX_train, boolean_lemy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(BERN_LEM_NB, boolean_lemX_train, boolean_lemy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(BERN_LEM_NB.score(boolean_lemX_test, boolean_lemy_test))
score_test_SVM_CV = BERN_LEM_NB.score(boolean_lemX_test, boolean_lemy_test)

print('\n')

print('BERN NGRAM MNB')
print('The training score is:')
train_score = BERN_NGRAMNB.score(gram12_booleanX_train, gram12_booleany_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(BERN_NGRAMNB, gram12_booleanX_train, gram12_booleany_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(BERN_NGRAMNB.score(gram12_booleanX_test, gram12_booleany_test))
score_test_SVM_CV = BERN_NGRAMNB.score(gram12_booleanX_test, gram12_booleany_test)

"""### Football SVM"""

# Define a funciton to find the optimal parameters for the SVM
def svc_param_selection(X, y, nfolds, kernel, c_range, gamma_range):
    Cs = list(c_range)
    gammas = list(gamma_range)
    param_grid = {'C': Cs, 'gamma':gammas}
    grid_search = GridSearchCV(svm.SVC(kernel = kernel), param_grid, cv = nfolds)
    grid_search.fit(X, y)
    return grid_search.best_params_

#print("Best Parameters for Linear SVM with CV_NORM data:\n")
#print(svc_param_selection(CVX_train, CVy_train, 4, 'linear', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

#print('\n')

#print("Best Parameters for Linear SVM with TFIDF data:\n")
#print(svc_param_selection(TFX_train, TFy_train, 4, 'linear', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

#print('\n')

#print("Best Parameters for Poly SVM with CV_NORM data:\n")
#print(svc_param_selection(CVX_train, CVy_train, 4, 'poly', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

#print('\n')

#print("Best Parameters for Poly SVM with TFIDF data:\n")
#print(svc_param_selection(TFX_train, TFy_train, 4, 'poly', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

#print('\n')

#print("Best Parameters for Radial SVM with CV_NORM data:\n")
#print(svc_param_selection(CVX_train, CVy_train, 4, 'rbf', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

#print('\n')

#print("Best Parameters for Radial SVM with TFIDF data:\n")
#print(svc_param_selection(TFX_train, TFy_train, 4, 'rbf', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

# Use the grid search to find the best parameters for this data set and the kernel. Start with the CV_Norm set 

# Linear kernel:  {'C': 0.201, 'gamma': 0.001}

linear_SVM = svm.SVC(C = 0.201, gamma = .001, kernel = 'linear')
LIN_MODEL = linear_SVM.fit(CVX_train, CVy_train)

LIN_PRED = LIN_MODEL.predict(CVX_test)
cnf_matrix = confusion_matrix(CVy_test, LIN_PRED)

print('Linear SVM with CV_Norm Data:\n', cnf_matrix)

disp = plot_confusion_matrix(LIN_MODEL, CVX_test, CVy_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for CV data SVM with Linear Kernel: \n')
print(classification_report(CVy_test, LIN_PRED))


print('\n')


# Linear Kernel with TFIDF data 

# TFIDF linear Kernel: {'C': 0.801, 'gamma': 0.001}
linear_tfidf = svm.SVC(C = 0.801, kernel = 'linear', gamma = .001)
LIN_MODEL_TFIDF = linear_tfidf.fit(TFX_train, TFy_train)

LIN_PRED_TFIDF = LIN_MODEL_TFIDF.predict(TFX_test)
conf_matrix = confusion_matrix(TFy_test, LIN_PRED_TFIDF)

print('Linear SVM with TFIDF Data:\n', cnf_matrix)

disp = plot_confusion_matrix(LIN_MODEL_TFIDF, TFX_test, TFy_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for TFIDF data SVM with Linear Kernel: \n')
print(classification_report(TFy_test, LIN_PRED_TFIDF))


print('\n')

# Linear Kernel with NGRAMS data 

# NGRAM linear Kernel: {'C': 0.801, 'gamma': 0.001}
linear_ngram = svm.SVC(C = 0.801, kernel = 'linear', gamma = .001)
LIN_MODEL_NGRAM = linear_ngram.fit(gram12X_train, gram12y_train)

LIN_PRED_NGRAM = LIN_MODEL_NGRAM.predict(gram12X_test)
conf_matrix = confusion_matrix(gram12y_test, LIN_PRED_NGRAM)

print('Linear SVM with NGRAM Data:\n', cnf_matrix)

disp = plot_confusion_matrix(LIN_MODEL_NGRAM, gram12X_test, gram12y_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for NGRAM data SVM with Linear Kernel: \n')
print(classification_report(gram12y_test, LIN_PRED_NGRAM))


print('\n')




# Polynomial kernel norm data set 

# Poly kernel: {'C': 0.001, 'gamma': 0.6010000000000001}
poly_SVM = svm.SVC(C = 0.001, kernel = 'poly', gamma = 0.601)
POLY_MODEL = poly_SVM.fit(CVX_train, CVy_train)

POLY_PRED = POLY_MODEL.predict(CVX_test)
cnf_matrix = confusion_matrix(CVy_test, POLY_PRED)

print('Polynomial SVM with CV_NORM Data:\n', cnf_matrix)

disp = plot_confusion_matrix(POLY_MODEL, CVX_test, CVy_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for CV data SVM with Polynomial Kernel: \n')
print(classification_report(CVy_test, POLY_PRED))

print('\n')



# Poly Kernel for TFIDF 

# Poly kernel: {'C': 0.801, 'gamma': 0.901}

poly_tfidf = svm.SVC(C=0.801, kernel = 'poly', gamma = 0.901)
POLY_MODEL_TFIDF = poly_tfidf.fit(TFX_train, TFy_train)

POLY_PRED_TFIDF = POLY_MODEL_TFIDF.predict(TFX_test)
cnf_matrix = confusion_matrix(TFy_test, POLY_PRED_TFIDF)

print('Polynomial SVM with TFIDF Data:\n', cnf_matrix)

disp = plot_confusion_matrix(POLY_MODEL_TFIDF, TFX_test, TFy_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for TFIDF data SVM with Polynomial Kernel: \n')
print(classification_report(TFy_test, POLY_PRED_TFIDF))

print('\n')

# Poly Kernel for NGRAM 

# Poly kernel: {'C': 0.801, 'gamma': 0.901}

poly_NGRAM = svm.SVC(C=0.801, kernel = 'poly', gamma = 0.901)
POLY_MODEL_NGRAM = poly_NGRAM.fit(gram12X_train, gram12y_train)

POLY_PRED_NGRAM = POLY_MODEL_NGRAM.predict(gram12X_test)
cnf_matrix = confusion_matrix(gram12y_test, POLY_PRED_NGRAM)

print('Polynomial SVM with NGRAM Data:\n', cnf_matrix)

disp = plot_confusion_matrix(POLY_MODEL_NGRAM, gram12X_test, gram12y_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for NGRAM data SVM with Polynomial Kernel: \n')
print(classification_report(gram12y_test, POLY_PRED_NGRAM))

print('\n')


# Radial kernel norm data set 

# Radial kernel: {'C': 0.901, 'gamma': 0.101}
rad_SVM = svm.SVC(C = 0.901, kernel = 'rbf', gamma = 0.101)
RAD_MODEL = rad_SVM.fit(CVX_train, CVy_train)

RAD_PRED = RAD_MODEL.predict(CVX_test)
cnf_matrix = confusion_matrix(CVy_test, RAD_PRED)

print('Radial SVM with CV_NORM Data:\n', cnf_matrix)

disp = plot_confusion_matrix(RAD_MODEL, CVX_test, CVy_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for CV data SVM with Radial Kernel: \n')
print(classification_report(CVy_test, RAD_PRED))

print('\n')



# Radial Kernel for TFIDF 

# Radial kernel: {'C': 0.901, 'gamma': 0.901}
rad_tfidf = svm.SVC(C=0.901, kernel = 'rbf', gamma = 0.901)
RAD_MODEL_TFIDF = rad_tfidf.fit(TFX_train, TFy_train)

RAD_PRED_TFIDF = RAD_MODEL_TFIDF.predict(TFX_test)
cnf_matrix = confusion_matrix(TFy_test, RAD_PRED_TFIDF)

print('Radial SVM with TFIDF Data:\n', cnf_matrix)

disp = plot_confusion_matrix(RAD_MODEL_TFIDF, TFX_test, TFy_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for TFIDF data SVM with Radial Kernel: \n')
print(classification_report(TFy_test, RAD_PRED_TFIDF))
print('\n')

# Radial Kernel for NGRAM 

# Radial kernel: {'C': 0.901, 'gamma': 0.901}
rad_ngram = svm.SVC(C=0.901, kernel = 'rbf', gamma = 0.901)
RAD_MODEL_NGRAM = rad_ngram.fit(gram12X_train, gram12y_train)

RAD_PRED_NGRAM = RAD_MODEL_NGRAM.predict(gram12X_test)
cnf_matrix = confusion_matrix(gram12y_test, RAD_PRED_NGRAM)

print('Radial SVM with NGRAM Data:\n', cnf_matrix)

disp = plot_confusion_matrix(RAD_MODEL_NGRAM, gram12X_test, gram12y_test, cmap = plt.cm.Blues)

print('\n')

print('Classification report for NGRAM data SVM with Radial Kernel: \n')
print(classification_report(gram12y_test, RAD_PRED_NGRAM))

# Cross Validations and Training Accuracies

# Cross Validation and Training Accuracies 
print('Linear SVM Norm Data')
print('The training score is:')
train_score = LIN_MODEL.score(CVX_train, CVy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(LIN_MODEL, CVX_train, CVy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(LIN_MODEL.score(CVX_test, CVy_test))
score_test_SVM_CV = BERNNB_model.score(BERNX_test, BERNy_test)


print('\n')

print('Linear SVM TFIDF')
print('The training score is:')
train_score = LIN_MODEL_TFIDF.score(TFX_train, TFy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(LIN_MODEL_TFIDF, TFX_train, TFy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(LIN_MODEL_TFIDF.score(TFX_test, TFy_test))
score_test_SVM_CV = LIN_MODEL_TFIDF.score(TFX_test, TFy_test)

print('\n')

print('Linear SVM NGRAM')
print('The training score is:')
train_score = LIN_MODEL_NGRAM.score(gram12X_train, gram12y_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(LIN_MODEL_NGRAM, gram12X_train, gram12y_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(LIN_MODEL_NGRAM.score(gram12X_test, gram12y_test))
score_test_SVM_CV = LIN_MODEL_NGRAM.score(gram12X_test, gram12y_test)

print('\n')

print('Poly SVM Norm Data')
print('The training score is:')
train_score = POLY_MODEL.score(CVX_train, CVy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(POLY_MODEL, CVX_train, CVy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(POLY_MODEL.score(CVX_test, CVy_test))
score_test_SVM_CV = POLY_MODEL.score(TFX_test, TFy_test)

print('\n')

print('Poly SVM TFIDF Data')
print('The training score is:')
train_score = POLY_MODEL_TFIDF.score(TFX_train, TFy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(POLY_MODEL_TFIDF, TFX_train, TFy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(POLY_MODEL_TFIDF.score(TFX_test, TFy_test))
score_test_SVM_CV = POLY_MODEL_TFIDF.score(TFX_test, TFy_test)

print('\n')

print('Poly SVM NGRAM Data')
print('The training score is:')
train_score = POLY_MODEL_NGRAM.score(gram12X_train, gram12y_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(POLY_MODEL_NGRAM, gram12X_train, gram12y_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(POLY_MODEL_NGRAM.score(gram12X_test, gram12y_test))
score_test_SVM_CV = POLY_MODEL_NGRAM.score(gram12X_test, gram12y_test)

print('\n')

print('Radial SVM Norm Data')
print('The training score is:')
train_score = RAD_MODEL.score(CVX_train, CVy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(RAD_MODEL, CVX_train, CVy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(RAD_MODEL.score(TFX_test, TFy_test))
score_test_SVM_CV = RAD_MODEL.score(TFX_test, TFy_test)

print('\n')

print('Radial SVM TFIDF Data')
print('The training score is:')
train_score = RAD_MODEL_TFIDF.score(TFX_train, TFy_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(RAD_MODEL_TFIDF, TFX_train, TFy_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(RAD_MODEL_TFIDF.score(TFX_test, TFy_test))
score_test_SVM_CV = RAD_MODEL_TFIDF.score(TFX_test, TFy_test)

print('\n')

print('Radial SVM NGRAM Data')
print('The training score is:')
train_score = RAD_MODEL_NGRAM.score(gram12X_train, gram12y_train)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(RAD_MODEL_NGRAM, gram12X_train, gram12y_train, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(RAD_MODEL_NGRAM.score(gram12X_test, gram12y_test))
score_test_SVM_CV = RAD_MODEL_NGRAM.score(gram12X_test, gram12y_test)

#######################
###   Linear SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=.1)

#Fitting the classifier 
SVM_CV_gram12=SVM_Model1.fit(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(GCV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(Gtest_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, GCV_gram12_Train, Gtrain_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV_gram12, GCV_gram12_Test, Gtest_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

"""# Golf

## Golf Data Prep
"""

#Creating empty lists that will be appended to from the loop
#Empty term label
GtermLabel=[]
#Empty country label
GcountryLabel=[]
#Empty title label
GtitleList=[]
#Empty urlAdd list
GurlAddrList=[]
#Empty provider list
GproviderLabel=[]
#Empty date published list
GdatePublishedList = []
#Empty description content list
GdescList = []

#Opening the raw review file and reading the first line which are the headers
with open('/content/gdrive/MyDrive/train_data_group_3_final.csv','r') as FILE:
    FILE.readline()
    #Now that the file pointer has skipped the header row the following loop will append the review text into the corresponding empty lists
    for row in FILE:
        #Splitting the label from the review elements
        term, country, title, url, provider, published, description =row.split(",", 6)
        if term == "golf":
          #Appending
          GdescList.append(description)
          #Appending
          GtermLabel.append(term)
          #Appending
          GcountryLabel.append(country)
          #Appending
          GtitleList.append(title)
          #Appending
          GurlAddrList.append(url)
          #Appending
          GproviderLabel.append(provider)
          #Appending
          GdatePublishedList.append(published)

len(GtermLabel)

#Code from https://scikit-learn.org/stable/modules/feature_extraction.html
#6.2.3.10. Customizing the vectorizer classes

class LemmaTokenizer:
     def __init__(self):
         self.wnl = WordNetLemmatizer()
     def __call__(self, doc):
         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]
     
#Defining the CountVectorizer using the input = 'content' using the 'word' analyzer
CV=CountVectorizer(input='content',
                        analyzer = 'word',
                        stop_words='english',
                        lowercase = True)

#Defining the TfidfVectorizer using the input = 'content' using the 'word' analyzer
TF=TfidfVectorizer(input='content',
                        analyzer = 'word',
                        use_idf=True,
                        stop_words='english',
                        lowercase = True)                  

#Defining the CountVectorizer using the input = 'content' using ngrams                
CV_gram12 = CountVectorizer(encoding='latin-1', 
                                          ngram_range=(1,2), 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)

#Defining the CountVectorizer using the input = 'content' using boolean values 
CV_boolean = CountVectorizer(encoding='latin-1',
                                          binary=True, 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)


#Defining the CountVectorizer using the input = 'content' using the 'word' analyzer and boolean values 
CV_boolean_lem = CountVectorizer(encoding='latin-1',
                                           tokenizer=LemmaTokenizer(),
                                           analyzer = 'word',
                                           binary=True,
                                           min_df=5, 
                                           stop_words='english',
                                           lowercase = True)

#Defining the CountVectorizer using the input = 'content' using ngrams  and boolean values
CV_gram12_boolean = CountVectorizer(encoding='latin-1',
                                          binary=True,
                                          ngram_range=(1,2), 
                                          min_df=5, 
                                          stop_words='english',
                                          lowercase = True)

#Transforming the content, using the description list, to a document term matrix array
GX_CV=CV.fit_transform(GdescList)
GX_TF=TF.fit_transform(GdescList)
GX_CV_gram12=CV_gram12.fit_transform(GdescList)
GX_CV_boolean=CV_boolean.fit_transform(GdescList)
GX_CV_boolean_lem=CV_boolean_lem.fit_transform(GdescList)
GX_CV_gram12_boolean=CV_gram12_boolean.fit_transform(GdescList)

#Setting the feature names to a columns list
GColNamesCV=CV.get_feature_names()
GColNamesTF=TF.get_feature_names()
GColNamesCV_gram12=CV_gram12.get_feature_names()
GColNamesCV_boolean=CV_boolean.get_feature_names()
GColNamestCV_boolean_lem=CV_boolean_lem.get_feature_names()
GColNamesCV_gram12_boolean=CV_gram12_boolean.get_feature_names()

#Creating the dataframes
Gcountry_DF_CV = pd.DataFrame(GX_CV.toarray(), columns=GColNamesCV)
Gcountry_DF_TF = pd.DataFrame(GX_TF.toarray(), columns=GColNamesTF)
Gcountry_DF_CV_gram12 = pd.DataFrame(GX_CV_gram12.toarray(), columns=GColNamesCV_gram12)
Gcountry_DF_CV_boolean = pd.DataFrame(GX_CV_boolean.toarray(), columns=GColNamesCV_boolean)
Gcountry_DF_CV_boolean_lem = pd.DataFrame(GX_CV_boolean_lem.toarray(), columns=GColNamestCV_boolean_lem)
Gcountry_DF_CV_gram12_boolean = pd.DataFrame(GX_CV_gram12_boolean.toarray(), columns=GColNamesCV_gram12_boolean)

#Getting the sums of each vector in the array 
Gcv_count = GX_CV.toarray().sum(axis=0)

Gtokens_CV = CV.get_feature_names()

#Merging the token names and their frequencies of the Count_Vectorizer array into a dataframe
Gtoken_count_CV = pd.DataFrame(Gcv_count, index=Gtokens_CV, columns=['counts'])

#Sorting the dataframe by frequency count highest to lowest
Gtoken_count_CV.sort_values(by ='counts', ascending = False).head(20)

#Creating a function that will return a result of TRUE if digits are present in a string
def Logical_Numbers_Present(anyString):
    return any(char.isdigit() for char in anyString)

#creating a loop to iterate through the dataframes and droping numbers and words that have less than 3 letters

for nextcol in Gcountry_DF_CV.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        Gcountry_DF_CV=Gcountry_DF_CV.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        Gcountry_DF_CV=Gcountry_DF_CV.drop([nextcol], axis=1)

for nextcol in Gcountry_DF_TF.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        Gcountry_DF_TF=Gcountry_DF_TF.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        Gcountry_DF_TF=Gcountry_DF_TF.drop([nextcol], axis=1)

for nextcol in Gcountry_DF_CV_gram12.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        Gcountry_DF_CV_gram12=Gcountry_DF_CV_gram12.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        Gcountry_DF_CV_gram12=Gcountry_DF_CV_gram12.drop([nextcol], axis=1)

for nextcol in Gcountry_DF_CV_boolean.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        Gcountry_DF_CV_boolean=Gcountry_DF_CV_boolean.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        Gcountry_DF_CV_boolean=Gcountry_DF_CV_boolean.drop([nextcol], axis=1)

for nextcol in Gcountry_DF_CV_boolean_lem.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        Gcountry_DF_CV_boolean_lem=Gcountry_DF_CV_boolean_lem.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        Gcountry_DF_CV_boolean_lem=Gcountry_DF_CV_boolean_lem.drop([nextcol], axis=1)

for nextcol in Gcountry_DF_CV_gram12_boolean.columns:
    LogResult=Logical_Numbers_Present(nextcol)
    if(LogResult==True):
        Gcountry_DF_CV_gram12_boolean=Gcountry_DF_CV_gram12_boolean.drop([nextcol], axis=1)
    #Dropping vectors that have less than 3 characters in the column name
    elif(len(str(nextcol))<=3):
        Gcountry_DF_CV_gram12_boolean=Gcountry_DF_CV_gram12_boolean.drop([nextcol], axis=1)

#inserting the country label list into the dataframes
Gcountry_DF_CV.insert(loc=0, column='LABEL', value=GcountryLabel)
Gcountry_DF_TF.insert(loc=0, column='LABEL', value=GcountryLabel)
Gcountry_DF_CV_gram12.insert(loc=0, column='LABEL', value=GcountryLabel)
Gcountry_DF_CV_boolean.insert(loc=0, column='LABEL', value=GcountryLabel)
Gcountry_DF_CV_boolean_lem.insert(loc=0, column='LABEL', value=GcountryLabel)
Gcountry_DF_CV_gram12_boolean.insert(loc=0, column='LABEL', value=GcountryLabel)

rd.seed(1234)

#using sklearn package to set up a test & train set for each of the datasets
Gtrain1, Gtest1 = train_test_split(Gcountry_DF_CV, test_size=0.2, random_state = 1)
print(Gtrain1.shape, Gtest1.shape)
Gtrain2, Gtest2 = train_test_split(Gcountry_DF_TF, test_size=0.2, random_state = 1)
print(Gtrain2.shape, Gtest2.shape)
Gtrain3, Gtest3 = train_test_split(Gcountry_DF_CV_gram12, test_size=0.2, random_state = 1)
print(Gtrain3.shape, Gtest3.shape)
Gtrain4, Gtest4 = train_test_split(Gcountry_DF_CV_boolean, test_size=0.2, random_state = 1)
print(Gtrain4.shape, Gtest4.shape)
Gtrain5, Gtest5 = train_test_split(Gcountry_DF_CV_boolean_lem, test_size=0.2, random_state = 1)
print(Gtrain5.shape, Gtest5.shape)
Gtrain6, Gtest6 = train_test_split(Gcountry_DF_CV_gram12_boolean, test_size=0.2, random_state = 1)
print(Gtrain6.shape, Gtest6.shape)

#################
#   Test Set    #
#################

#Isolating the labels from the test sets into their own dataframe
Gtest_CV_Labels=Gtest1["LABEL"]
Gtest_TF_Labels=Gtest2["LABEL"]
Gtest_CV_gram12_Labels=Gtest3["LABEL"]
Gtest_CV_boolean_Labels=Gtest4["LABEL"]
Gtest_CV_boolean_lem_Labels=Gtest5["LABEL"]
Gtest_CV_gram12_boolean_Labels=Gtest6["LABEL"]

#Isolating the content from the test sets by dropping the labels
GCV_Test = Gtest1.drop(["LABEL"], axis=1)
GTF_Test = Gtest2.drop(["LABEL"], axis=1)
GCV_gram12_Test = Gtest3.drop(["LABEL"], axis=1)
GCV_boolean_Test = Gtest4.drop(["LABEL"], axis=1)
GCV_boolean_lem_Test = Gtest5.drop(["LABEL"], axis=1)
GCV_gram12_boolean_Test = Gtest6.drop(["LABEL"], axis=1)

##################
#   Train Set    #
##################

#Isolating the labels from the train sets into their own dataframe

Gtrain_CV_Labels=Gtrain1["LABEL"]
#finding the category frequency in the training set
Gunique, Gcounts = np.unique(Gtrain_CV_Labels, return_counts=True)
print(np.asarray((Gunique, Gcounts)))

Gtrain_TF_Labels=Gtrain2["LABEL"]
#finding the category frequency in the training set
Gunique, Gcounts = np.unique(Gtrain_TF_Labels, return_counts=True)
print(np.asarray((Gunique, Gcounts)))

Gtrain_CV_gram12_Labels=Gtrain3["LABEL"]
#finding the category frequency in the training set
Gunique, Gcounts = np.unique(Gtrain_CV_gram12_Labels, return_counts=True)
print(np.asarray((Gunique, Gcounts)))

Gtrain_CV_boolean_Labels=Gtrain4["LABEL"]
#finding the category frequency in the training set
Gunique, Gcounts = np.unique(Gtrain_CV_boolean_Labels, return_counts=True)
print(np.asarray((Gunique, Gcounts)))

Gtrain_CV_boolean_lem_Labels=Gtrain5["LABEL"]
#finding the category frequency in the training set
Gunique, Gcounts = np.unique(Gtrain_CV_boolean_lem_Labels, return_counts=True)
print(np.asarray((Gunique, Gcounts)))

Gtrain_CV_gram12_boolean_Labels=Gtrain6["LABEL"]
#finding the category frequency in the training set
Gunique, Gcounts = np.unique(Gtrain_CV_gram12_boolean_Labels, return_counts=True)
print(np.asarray((Gunique, Gcounts)))

#Isolating the content from the train sets by dropping the labels
GCV_Train = Gtrain1.drop(["LABEL"], axis=1)
GTF_Train = Gtrain2.drop(["LABEL"], axis=1)
GCV_gram12_Train = Gtrain3.drop(["LABEL"], axis=1)
GCV_boolean_Train = Gtrain4.drop(["LABEL"], axis=1)
GCV_boolean_lem_Train = Gtrain5.drop(["LABEL"], axis=1)
GCV_gram12_boolean_Train = Gtrain6.drop(["LABEL"], axis=1)

def show_top20(classifier, vectorizer):
    neg_class_prob_sorted = classifier.feature_log_prob_[0, :].argsort()
    pos_class_prob_sorted = classifier.feature_log_prob_[1, :].argsort()
    print("20 most important words for choosing GB:")
    print(np.take(vectorizer.get_feature_names(), neg_class_prob_sorted[-20:]))
    print("20 most important words for choosing US:")
    print(np.take(vectorizer.get_feature_names(), pos_class_prob_sorted[-20:]))

def show_most_informative_features(vectorizer, clf, n=20):
    feature_names = vectorizer.get_feature_names()
    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
    for (coef_1, fn_1), (coef_2, fn_2) in top:
        print("\t%.4f\t%-15s\t\t%.4f\t%-15s" % (coef_1, fn_1, coef_2, fn_2))

"""## Golf Naive Bayes"""

####################################################################
########################### Naive Bayes ############################
####################################################################
#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit
#Declaring the classifier
MyModelNB= MultinomialNB()

################################################################################

#Fitting the classifier 
GNB_CV=MyModelNB.fit(GCV_Train, Gtrain_CV_Labels)
#Using the model to predict the classification of test set 
GPrediction_CV = GNB_CV.predict(GCV_Test)
#Array of the target probabilities
#print(np.round(NB_CV.predict_proba(CV_Test),2))

#Confusion Matrix
Gcnf_matrix_CV = confusion_matrix(Gtest_CV_Labels, GPrediction_CV)
print("\nThe NB_CV confusion matrix is:")
print(Gcnf_matrix_CV)
print("\nThe NB_CV train accuracy is:")
GNB_CV_train_score = GNB_CV.score(GCV_Train, Gtrain_CV_Labels)
print(GNB_CV_train_score)
#Finding the 10-fold cross-validation on the train set
Gscores_CV = cross_val_score(GNB_CV, GCV_Train, Gtrain_CV_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_CV Train accuracy: %0.2f (+/- %0.2f)' % (Gscores_CV.mean(), Gscores_CV.std() * 2))
Gscores_CV_Mean = Gscores_CV.mean()
print("\nThe NB_CV test accuracy is:")
print(GNB_CV.score(GCV_Test, Gtest_CV_Labels))
Gscore_test_NB_CV = GNB_CV.score(GCV_Test, Gtest_CV_Labels)

show_top20(GNB_CV, CV)

print("CV Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV, GNB_CV)

disp = plot_confusion_matrix(GNB_CV, GCV_Test, Gtest_CV_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################

#Fitting the classifier 
GNB_TF=MyModelNB.fit(GTF_Train, Gtrain_TF_Labels)
#Using the model to predict the classification of test set 
GPrediction_TF = GNB_TF.predict(GTF_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(NB_TF.predict_proba(TF_Test),2))

#Confusion Matrix
Gcnf_matrix_TF = confusion_matrix(Gtest_TF_Labels, GPrediction_TF)
print("\nThe NB_TF confusion matrix is:")
print(Gcnf_matrix_TF)
print("\nThe NB_TF train accuracy is:")
GNB_TF_train_score = GNB_TF.score(GTF_Train, Gtrain_TF_Labels)
print(GNB_TF_train_score)
#Finding the 10-fold cross-validation on the train set
Gscores_TF = cross_val_score(GNB_TF, GTF_Train, Gtrain_TF_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_TF Train accuracy: %0.2f (+/- %0.2f)' % (Gscores_TF.mean(), Gscores_TF.std() * 2))
Gscores_TF_Mean = Gscores_TF.mean()
print("\nThe NB_TF test accuracy is:")
print(GNB_TF.score(GTF_Test, Gtest_TF_Labels))
Gscore_test_NB_TF = GNB_TF.score(GTF_Test, Gtest_TF_Labels)

show_top20(MyModelNB, TF)

print("TF Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(TF, GNB_TF)

disp = plot_confusion_matrix(GNB_TF, GTF_Test, Gtest_TF_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################

#Fitting the classifier 
GNB_CV_gram12=MyModelNB.fit(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
#Using the model to predict the classification of test set 
GPrediction_CV_gram12 = GNB_CV_gram12.predict(GCV_gram12_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(NB_CV_gram12.predict_proba(CV_gram12_Test),2))

#Confusion Matrix
Gcnf_matrix_CV_gram12 = confusion_matrix(Gtest_CV_gram12_Labels, GPrediction_CV_gram12)
print("\nThe NB_CV_gram12 confusion matrix is:")
print(Gcnf_matrix_CV_gram12)
print("\nThe NB_CV_gram12 train accuracy is:")
GNB_CV_gram12_train_score = GNB_CV_gram12.score(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
print(GNB_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
Gscores_CV_gram12 = cross_val_score(GNB_CV_gram12, GCV_gram12_Train, Gtrain_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation NB_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (Gscores_CV_gram12.mean(), Gscores_CV_gram12.std() * 2))
Gscores_CV_gram12_Mean = Gscores_CV_gram12.mean()
print("\nThe NB_CV_gram12 test accuracy is:")
print(GNB_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels))
Gscore_test_NB_CV_gram12 = GNB_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels)

show_top20(MyModelNB, CV_gram12)

print("CV NGRAM Multinomial Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_gram12, GNB_CV_gram12)

disp = plot_confusion_matrix(GNB_CV_gram12, GCV_gram12_Test, Gtest_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

################################################################################
###                        Naive Bayes Bernoulli                             ###
################################################################################

bernoulliNB = BernoulliNB()

#Fitting the classifier 
GbernoulliNB_CV_boolean_lem = bernoulliNB.fit(GCV_boolean_lem_Train, Gtrain_CV_boolean_lem_Labels)
#Using the model to predict the classification of test set 
GPrediction_CV_boolean_lem = GbernoulliNB_CV_boolean_lem.predict(GCV_boolean_lem_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_boolean_lem.predict_proba(CV_boolean_lem_Test),2))

#Confusion Matrix
Gcnf_matrix_tfidf_boolean = confusion_matrix(Gtest_CV_boolean_lem_Labels, GPrediction_CV_boolean_lem)
print("\nThe bernoulliNB_CV_boolean_lem confusion matrix is:")
print(Gcnf_matrix_tfidf_boolean)
print("\nThe bernoulliNB_CV_boolean_lem train accuracy is:")
GbernoulliNB_CV_boolean_lem_train_score = GbernoulliNB_CV_boolean_lem.score(GCV_boolean_lem_Train, Gtrain_CV_boolean_lem_Labels)
print(GbernoulliNB_CV_boolean_lem_train_score)
#Finding the 10-fold cross-validation on the train set
Gscores_CV_boolean_lem = cross_val_score(GbernoulliNB_CV_boolean_lem, GCV_boolean_lem_Train, Gtrain_CV_boolean_lem_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_boolean_lem Train accuracy: %0.2f (+/- %0.2f)' % (Gscores_CV_boolean_lem.mean(), Gscores_CV_boolean_lem.std() * 2))
Gscores_CV_boolean_lem_Mean = Gscores_CV_boolean_lem.mean()
print("\nThe bernoulliNB_CV_boolean_lem test accuracy is:")
print(GbernoulliNB_CV_boolean_lem.score(GCV_boolean_lem_Test, Gtest_CV_boolean_lem_Labels))
Gscore_test_bernoulliNB_CV_boolean_lem = GbernoulliNB_CV_boolean_lem.score(GCV_boolean_lem_Test, Gtest_CV_boolean_lem_Labels)
print('\n')

show_top20(bernoulliNB, CV_boolean_lem)
print('\n')

print("CV with Lemmatization Bernoulli Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_boolean_lem, GbernoulliNB_CV_boolean_lem)

disp = plot_confusion_matrix(GbernoulliNB_CV_boolean_lem, GCV_boolean_lem_Test, Gtest_CV_boolean_lem_Labels, cmap = plt.cm.Blues, values_format = '')
#########################################################################################################

#Fitting the classifier 
GbernoulliNB_CV_boolean = bernoulliNB.fit(GCV_boolean_Train , Gtrain_CV_boolean_Labels)
#Using the model to predict the classification of test set 
GPrediction_CV_boolean = GbernoulliNB_CV_boolean.predict(GCV_boolean_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_boolean.predict_proba(CV_boolean_Test),2))

#Confusion Matrix
Gcnf_matrix_CV_boolean = confusion_matrix(Gtest_CV_boolean_Labels, GPrediction_CV_boolean)
print("\nThe bernoulliNB_CV_boolean confusion matrix is:")
print(Gcnf_matrix_CV_boolean)
print("\nThe bernoulliNB_CV_boolean train accuracy is:")
GbernoulliNB_CV_boolean_train_score = GbernoulliNB_CV_boolean.score(GCV_boolean_Train, Gtrain_CV_boolean_Labels)
print(GbernoulliNB_CV_boolean_train_score)
#Finding the 10-fold cross-validation on the train set
Gscores_CV_boolean = cross_val_score(GbernoulliNB_CV_boolean, GCV_boolean_Train, Gtrain_CV_boolean_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_boolean Train accuracy: %0.2f (+/- %0.2f)' % (Gscores_CV_boolean.mean(), Gscores_CV_boolean.std() * 2))
Gscores_CV_boolean_Mean = Gscores_CV_boolean.mean()
print("\nThe bernoulliNB_CV_boolean test accuracy is:")
print(GbernoulliNB_CV_boolean.score(GCV_boolean_Test, Gtest_CV_boolean_Labels))
Gscore_test_bernoulliNB_CV_boolean = GbernoulliNB_CV_boolean.score(GCV_boolean_Test, Gtest_CV_boolean_Labels)
print('\n')

show_top20(GbernoulliNB_CV_boolean, CV_boolean)
print('\n')

print("CV Bernoulli Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_boolean, GbernoulliNB_CV_boolean)
print('\n')

disp = plot_confusion_matrix(GbernoulliNB_CV_boolean, GCV_boolean_Test, Gtest_CV_boolean_Labels, cmap = plt.cm.Blues, values_format = '')
#########################################################################################################

#Fitting the classifier 
GbernoulliNB_CV_gram12_boolean = bernoulliNB.fit(GCV_gram12_boolean_Train , Gtrain_CV_gram12_boolean_Labels)
#Using the model to predict the classification of test set 
GPrediction_CV_gram12_boolean = GbernoulliNB_CV_gram12_boolean.predict(GCV_gram12_boolean_Test)
#Array of the target probabilities (f,t) on the test set
#print(np.round(bernoulliNB_CV_gram12_boolean.predict_proba(CV_gram12_boolean_Sentiment_Test),2))

#Confusion Matrix
Gcnf_matrix_CV_gram12_boolean = confusion_matrix(Gtest_CV_gram12_boolean_Labels, GPrediction_CV_gram12_boolean)
print("\nThe bernoulliNB_CV_gram12_boolean confusion matrix is:")
print(Gcnf_matrix_CV_gram12_boolean)
print("\nThe bernoulliNB_CV_gram12_boolean train accuracy is:")
GbernoulliNB_CV_gram12_boolean_train_score = GbernoulliNB_CV_gram12_boolean.score(GCV_gram12_boolean_Train, Gtrain_CV_gram12_boolean_Labels)
print(GbernoulliNB_CV_gram12_boolean_train_score)
#Finding the 10-fold cross-validation on the train set
Gscores_CV_gram12_boolean = cross_val_score(GbernoulliNB_CV_gram12_boolean, GCV_gram12_boolean_Train, Gtrain_CV_gram12_boolean_Labels, cv =10)
print('\n10-Fold Cross-Validation bernoulliNB_CV_gram12_boolean Train accuracy: %0.2f (+/- %0.2f)' % (Gscores_CV_gram12_boolean.mean(), Gscores_CV_gram12_boolean.std() * 2))
Gscores_CV_gram12_boolean_Mean = Gscores_CV_gram12_boolean.mean()
print("\nThe bernoulliNB_CV_gram12_boolean test accuracy is:")
print(GbernoulliNB_CV_gram12_boolean.score(GCV_gram12_boolean_Test, Gtest_CV_gram12_boolean_Labels))
Gscore_test_bernoulliNB_CV_gram12_boolean = GbernoulliNB_CV_gram12_boolean.score(GCV_gram12_boolean_Test, Gtest_CV_gram12_boolean_Labels)

show_top20(bernoulliNB, CV_gram12_boolean)
print('\n')

print("CV NGRAM Bernoulli Naive Bayes Most Informative Features\n")
show_most_informative_features(CV_gram12_boolean, GbernoulliNB_CV_gram12_boolean)
print('\n')

disp = plot_confusion_matrix(GbernoulliNB_CV_gram12_boolean, GCV_gram12_boolean_Test, Gtest_CV_gram12_boolean_Labels, cmap = plt.cm.Blues, values_format = '')

#########################################################################################################

"""## Golf SVM"""

# Define a funciton to find the optimal parameters for the SVM
def svc_param_selection(X, y, nfolds, kernel, c_range, gamma_range):
    Cs = list(c_range)
    gammas = list(gamma_range)
    param_grid = {'C': Cs, 'gamma':gammas}
    grid_search = GridSearchCV(svm.SVC(kernel = kernel), param_grid, cv = nfolds)
    grid_search.fit(X, y)
    return grid_search.best_params_

print("Best Parameters for Linear SVM with CVdata:\n")
print(svc_param_selection(GCV_Train, Gtrain_CV_Labels, 4, 'linear', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

print('\n')

print("Best Parameters for Linear SVM with TFIDF data:\n")
print(svc_param_selection(GTF_Train, Gtrain_TF_Labels, 4, 'linear', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

print('\n')

print("Best Parameters for Poly SVM with CV data:\n")
print(svc_param_selection(GCV_Train, Gtrain_CV_Labels, 4, 'poly', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

print('\n')

print("Best Parameters for Poly SVM with TFIDF data:\n")
print(svc_param_selection(GTF_Train, Gtrain_TF_Labels, 4, 'poly', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

print('\n')

print("Best Parameters for Radial SVM with CV data:\n")
print(svc_param_selection(GCV_Train, Gtrain_CV_Labels, 4, 'rbf', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

print('\n')

print("Best Parameters for Radial SVM with TFIDF data:\n")
print(svc_param_selection(GTF_Train, Gtrain_TF_Labels, 4, 'rbf', np.arange(.001, 1.001, .1), np.arange(.001, 1.001, .1)))

# Use the grid search to find the best parameters for this data set and the kernel. Start with the CV_Norm set 

# Linear Kernel with CV data 

linear_SVM = svm.SVC(C = 0.201, gamma = .001, kernel = 'linear')
LIN_MODEL = linear_SVM.fit(GCV_Train, Gtrain_CV_Labels)

LIN_PRED = LIN_MODEL.predict(GCV_Test)
cnf_matrix = confusion_matrix(Gtest_CV_Labels, LIN_PRED)

print('Linear SVM with CV Data:\n', cnf_matrix)

disp = plot_confusion_matrix(LIN_MODEL, GCV_Test, Gtest_CV_Labels, cmap = plt.cm.Blues)

print('\n')

print('Classification report for CV data SVM with Linear Kernel: \n')
print(classification_report(Gtest_CV_Labels, LIN_PRED))

print('\n')

print('The training score is:')
train_score = LIN_MODEL.score(GCV_Train, Gtrain_CV_Labels)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(LIN_MODEL, GCV_Train, Gtrain_CV_Labels, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(LIN_MODEL.score(GCV_Test, Gtest_CV_Labels))
score_test_SVM_CV = LIN_MODEL.score(GCV_Test, Gtest_CV_Labels)
print('\n')


print('\n')


# Linear Kernel with TFIDF data 

linear_tfidf = svm.SVC(C = 0.901, kernel = 'linear', gamma = .001)
LIN_MODEL_TFIDF = linear_tfidf.fit(GTF_Train, Gtrain_TF_Labels)

LIN_PRED_TFIDF = LIN_MODEL_TFIDF.predict(GTF_Test)
conf_matrix = confusion_matrix(Gtest_TF_Labels, LIN_PRED_TFIDF)

print('Linear SVM with TFIDF Data:\n', cnf_matrix)

disp = plot_confusion_matrix(LIN_MODEL_TFIDF, GTF_Test, Gtest_TF_Labels, cmap = plt.cm.Blues)

print('\n')

print('Classification report for TFIDF data SVM with Linear Kernel: \n')
print(classification_report(Gtest_TF_Labels, LIN_PRED_TFIDF))


print('\n')

print('The training score is:')
train_score = LIN_MODEL_TFIDF.score(GTF_Train, Gtrain_TF_Labels)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(LIN_MODEL_TFIDF, GTF_Train, Gtrain_TF_Labels, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(LIN_MODEL_TFIDF.score(GTF_Test, Gtest_TF_Labels))
score_test_SVM_CV = LIN_MODEL_TFIDF.score(GTF_Test, Gtest_TF_Labels)
print('\n')


# Polynomial kernel CV data set 

poly_SVM = svm.SVC(C = 0.30100000000000005, kernel = 'poly', gamma = 0.101)
POLY_MODEL = poly_SVM.fit(GCV_Train, Gtrain_CV_Labels)

POLY_PRED = POLY_MODEL.predict(GCV_Test)
cnf_matrix = confusion_matrix(Gtest_CV_Labels, POLY_PRED)

print('Polynomial SVM with CV Data:\n', cnf_matrix)

disp = plot_confusion_matrix(POLY_MODEL, GCV_Test, Gtest_CV_Labels, cmap = plt.cm.Blues)

print('\n')

print('Classification report for CV data SVM with Polynomial Kernel: \n')
print(classification_report(Gtest_CV_Labels, POLY_PRED))

print('\n')

print('The training score is:')
train_score = POLY_MODEL.score(GCV_Train, Gtrain_CV_Labels)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(POLY_MODEL, GCV_Train, Gtrain_CV_Labels, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(POLY_MODEL.score(GCV_Test, Gtest_CV_Labels))
score_test_SVM_CV = POLY_MODEL.score(GCV_Test, Gtest_CV_Labels)
print('\n')


# Polynomial kernel TFIDF data set 

poly_tfidf = svm.SVC(C=0.001, kernel = 'poly', gamma = 0.001)
POLY_MODEL_TFIDF = poly_tfidf.fit(GTF_Train, Gtrain_TF_Labels)

POLY_PRED_TFIDF = POLY_MODEL_TFIDF.predict(GTF_Test)
cnf_matrix = confusion_matrix(Gtest_TF_Labels, POLY_PRED_TFIDF)

print('Polynomial SVM with TFIDF Data:\n', cnf_matrix)

disp = plot_confusion_matrix(POLY_MODEL_TFIDF, GTF_Test, Gtest_TF_Labels, cmap = plt.cm.Blues)

print('\n')

print('Classification report for TFIDF data SVM with Polynomial Kernel: \n')
print(classification_report(Gtest_TF_Labels, POLY_PRED_TFIDF))

print('\n')

print('The training score is:')
train_score = POLY_MODEL_TFIDF.score(GTF_Train, Gtrain_TF_Labels)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(POLY_MODEL_TFIDF, GTF_Train, Gtrain_TF_Labels, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(POLY_MODEL_TFIDF.score(GTF_Test, Gtest_TF_Labels))
score_test_SVM_CV = POLY_MODEL_TFIDF.score(GTF_Test, Gtest_TF_Labels)
print('\n')

# Radial kernel CV data set 

rad_SVM = svm.SVC(C = 0.901, kernel = 'rbf', gamma = 0.101)
RAD_MODEL = rad_SVM.fit(GCV_Train, Gtrain_CV_Labels)

RAD_PRED = RAD_MODEL.predict(GCV_Test)
cnf_matrix = confusion_matrix(Gtest_CV_Labels, RAD_PRED)

print('Radial SVM with CV Data:\n', cnf_matrix)

disp = plot_confusion_matrix(RAD_MODEL, GCV_Test, Gtest_CV_Labels, cmap = plt.cm.Blues)

print('\n')

print('Classification report for CV data SVM with Radial Kernel: \n')
print(classification_report(Gtest_CV_Labels, RAD_PRED))

print('\n')

print('The training score is:')
train_score = RAD_MODEL.score(GCV_Train, Gtrain_CV_Labels)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(RAD_MODEL, GCV_Train, Gtrain_CV_Labels, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(RAD_MODEL.score(GCV_Test, Gtest_CV_Labels))
score_test_SVM_CV = RAD_MODEL.score(GCV_Test, Gtest_CV_Labels)
print('\n')


# Radial Kernel for TFIDF data set

rad_tfidf = svm.SVC(C=0.901, kernel = 'rbf', gamma = 0.901)
RAD_MODEL_TFIDF = rad_tfidf.fit(GTF_Train, Gtrain_TF_Labels)

RAD_PRED_TFIDF = RAD_MODEL_TFIDF.predict(GTF_Test)
cnf_matrix = confusion_matrix(Gtest_TF_Labels, RAD_PRED_TFIDF)

print('Radial SVM with TFIDF Data:\n', cnf_matrix)

disp = plot_confusion_matrix(RAD_MODEL_TFIDF, GTF_Test, Gtest_TF_Labels, cmap = plt.cm.Blues)

print('\n')

print('Classification report for TFIDF data SVM with Radial Kernel: \n')
print(classification_report(Gtest_TF_Labels, RAD_PRED_TFIDF))

print('\n')

print('The training score is:')
train_score = RAD_MODEL_TFIDF.score(GTF_Train, Gtrain_TF_Labels)
print(train_score)
#Finding the 10-fold cross-validation on the train set
scores_cross_validation = cross_val_score(RAD_MODEL_TFIDF, GTF_Train, Gtrain_TF_Labels, cv =10)
print('\n')
print('\n10-Fold Cross-Validation Train accuracy: %0.2f (+/- %0.2f)' % (scores_cross_validation.mean(), scores_cross_validation.std() * 2))
scores_cross_validation_mean = scores_cross_validation.mean()
print('\n')
print("\nThe test accuracy is:")
print(RAD_MODEL_TFIDF.score(GTF_Test, Gtest_TF_Labels))
score_test_SVM_CV = RAD_MODEL_TFIDF.score(GTF_Test, Gtest_TF_Labels)

#######################
###   Linear SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model1 =LinearSVC(C=.1)

#Fitting the classifier 
SVM_CV_gram12=SVM_Model1.fit(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(GCV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(Gtest_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, GCV_gram12_Train, Gtrain_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model1.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

disp = plot_confusion_matrix(SVM_CV_gram12, GCV_gram12_Test, Gtest_CV_gram12_Labels, cmap = plt.cm.Blues, values_format = '')

#######################
###   Radial SVM    ###
#######################
#######################
##       NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model2 = sklearn.svm.SVC(C=100, kernel='rbf', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model2.fit(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(GCV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(Gtest_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, GCV_gram12_Train, Gtrain_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model2.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

#######################
###     Poly SVM    ###
#######################
#######################
###      NGRAMS     ###
#######################

#Declaring the classifier
SVM_Model3 = sklearn.svm.SVC(C=1, kernel='poly', degree=3, gamma="auto")

#Fitting the classifier 
SVM_CV_gram12=SVM_Model3.fit(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
#Using the model to predict the classification of test set 
Prediction_CV_gram12_SVM = SVM_CV_gram12.predict(GCV_gram12_Test)

#Confusion Matrix
cnf_matrix_CV_gram12_SVM = confusion_matrix(Gtest_CV_gram12_Labels, Prediction_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 confusion matrix is:")
print(cnf_matrix_CV_gram12_SVM)
print("\nThe SVM_CV_gram12 train accuracy is:")
SVM_CV_gram12_train_score = SVM_CV_gram12.score(GCV_gram12_Train, Gtrain_CV_gram12_Labels)
print(SVM_CV_gram12_train_score)
#Finding the 10-fold cross-validation on the train set
scores_CV_gram12_SVM = cross_val_score(SVM_CV_gram12, GCV_gram12_Train, Gtrain_CV_gram12_Labels, cv =10)
print('\n10-Fold Cross-Validation SVM_CV_gram12 Train accuracy: %0.2f (+/- %0.2f)' % (scores_CV_gram12_SVM.mean(), scores_CV_gram12_SVM.std() * 2))
scores_CV_gram12_Mean_SVM = scores_CV_gram12_SVM.mean()
print("\nThe SVM_CV_gram12 test accuracy is:")
print(SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels))
score_test_SVM_CV_gram12 = SVM_CV_gram12.score(GCV_gram12_Test, Gtest_CV_gram12_Labels)

# ALL features sorted by importance
#svm_sorted = SVM_Model3.coef_.argsort()
#print(np.take(CV_gram12.get_feature_names(), svm_sorted[-10:]))

"""# Model Comparison"""

#Reading in the accuracy results
model_compare = pd.read_excel('/content/gdrive/MyDrive/model_compare.xlsx')

##visualizing the expirements by Cross Validation and Test accuracy
##https://seaborn.pydata.org/generated/seaborn.scatterplot.html
##building a scatter plot in seaborn
ax = sns.scatterplot( x='Cross_Val_10fold_Train_Accuracy', y='Test_Accuracy', hue = 'topic', style = 'model', data=model_compare,  s=200)
ax.set(xlabel='10 Fold Cross Validation Accuracy', ylabel='Test Accuracy')
plt.show()



"""# Works Cited
Works Cited:
Dr. Gates, A.  Code pulled from 2SU Text Mining 736 Course files: 
•	Week3CodeExampleLabeledLessHardCSV - Sunday, October 18
•	Week3_CodeExample_Hard_csv - Sunday, October 18
•	Week4_CodeExample1_NB_Bern_SVM - Wednesday, October 21
•	HUGECodeonEverythingGates – Sunday, November 15th, 2020

"""